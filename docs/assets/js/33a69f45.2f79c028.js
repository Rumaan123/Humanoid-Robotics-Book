"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[868],{5702(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>c});var o=i(4848),s=i(8453);const t={sidebar_position:6},r="References and Bibliography",a={id:"references",title:"References and Bibliography",description:"Official Documentation and Specifications",source:"@site/docs/references.md",sourceDirName:".",slug:"/references",permalink:"/Humanoid-Robotics-Book/docs/references",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Conclusion: Synthesis and Future Directions",permalink:"/Humanoid-Robotics-Book/docs/conclusion"}},l={},c=[{value:"Official Documentation and Specifications",id:"official-documentation-and-specifications",level:2},{value:"Academic Research",id:"academic-research",level:2},{value:"Physical AI and Embodied Intelligence",id:"physical-ai-and-embodied-intelligence",level:2},{value:"Simulation and Digital Twins",id:"simulation-and-digital-twins",level:2},{value:"Perception and Navigation",id:"perception-and-navigation",level:2},{value:"Vision-Language-Action Systems",id:"vision-language-action-systems",level:2},{value:"Reinforcement Learning for Robotics",id:"reinforcement-learning-for-robotics",level:2},{value:"Humanoid Robotics",id:"humanoid-robotics",level:2},{value:"Large Language Models in Robotics",id:"large-language-models-in-robotics",level:2},{value:"Safety and Ethics in Robotics",id:"safety-and-ethics-in-robotics",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",hr:"hr",li:"li",ol:"ol",p:"p",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"references-and-bibliography",children:"References and Bibliography"}),"\n",(0,o.jsx)(n.h2,{id:"official-documentation-and-specifications",children:"Official Documentation and Specifications"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["ROS 2 Documentation. (2023). ",(0,o.jsx)(n.em,{children:"ROS 2 Documentation"}),". Open Robotics. ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/",children:"https://docs.ros.org/en/humble/"})]}),"\n",(0,o.jsxs)(n.li,{children:["NVIDIA Isaac. (2023). ",(0,o.jsx)(n.em,{children:"NVIDIA Isaac Documentation"}),". NVIDIA Corporation. ",(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/isaac/",children:"https://docs.nvidia.com/isaac/"})]}),"\n",(0,o.jsxs)(n.li,{children:["Gazebo. (2023). ",(0,o.jsx)(n.em,{children:"Gazebo Documentation"}),". Open Robotics. ",(0,o.jsx)(n.a,{href:"https://gazebosim.org/docs/",children:"https://gazebosim.org/docs/"})]}),"\n",(0,o.jsxs)(n.li,{children:["Unity Robotics. (2023). ",(0,o.jsx)(n.em,{children:"Unity Robotics Hub Documentation"}),". Unity Technologies. ",(0,o.jsx)(n.a,{href:"https://unity.com/solutions/industries/robotics",children:"https://unity.com/solutions/industries/robotics"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"academic-research",children:"Academic Research"}),"\n",(0,o.jsxs)(n.ol,{start:"5",children:["\n",(0,o.jsxs)(n.li,{children:["Brooks, R. A. (1991). Intelligence without representation. ",(0,o.jsx)(n.em,{children:"Artificial Intelligence"}),", 47(1-3), 139-159."]}),"\n",(0,o.jsxs)(n.li,{children:["Pfeifer, R., & Bongard, J. (2006). ",(0,o.jsx)(n.em,{children:"How the body shapes the way we think: A new view of intelligence"}),". MIT Press."]}),"\n",(0,o.jsxs)(n.li,{children:["Brooks, R. A. (1986). A robust layered control system for a mobile robot. ",(0,o.jsx)(n.em,{children:"IEEE Journal on Robotics and Automation"}),", 2(1), 14-23."]}),"\n",(0,o.jsxs)(n.li,{children:["Lakshmanan, K., et al. (2021). A survey of robot learning from demonstration. ",(0,o.jsx)(n.em,{children:"Journal of Machine Learning Research"}),", 22(1), 1-40."]}),"\n",(0,o.jsxs)(n.li,{children:["Kober, J., Bagnell, J. A., & Peters, J. (2013). Reinforcement learning in robotics: A survey. ",(0,o.jsx)(n.em,{children:"The International Journal of Robotics Research"}),", 32(11), 1238-1274."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"physical-ai-and-embodied-intelligence",children:"Physical AI and Embodied Intelligence"}),"\n",(0,o.jsxs)(n.ol,{start:"10",children:["\n",(0,o.jsxs)(n.li,{children:["Pfeifer, R., & Scheier, C. (1999). ",(0,o.jsx)(n.em,{children:"Understanding intelligence"}),". MIT Press."]}),"\n",(0,o.jsxs)(n.li,{children:["Clark, A. (2008). ",(0,o.jsx)(n.em,{children:"Supersizing the mind: Embodiment, action, and cognitive extension"}),". Oxford University Press."]}),"\n",(0,o.jsxs)(n.li,{children:["Hutto, D. D., & Myin, E. (2013). ",(0,o.jsx)(n.em,{children:"Radicalizing enactivism: Basic minds without content"}),". MIT Press."]}),"\n",(0,o.jsxs)(n.li,{children:["Metzinger, T. (Ed.). (2006). ",(0,o.jsx)(n.em,{children:"Being conscious: A brief introduction to the philosophy of mind"}),". MIT Press."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"simulation-and-digital-twins",children:"Simulation and Digital Twins"}),"\n",(0,o.jsxs)(n.ol,{start:"14",children:["\n",(0,o.jsxs)(n.li,{children:["Koos, S., et al. (2013). Fast visual perception and ground classification for realistic simulated legged robots. ",(0,o.jsx)(n.em,{children:"Robotica"}),", 31(7), 1133-1147."]}),"\n",(0,o.jsxs)(n.li,{children:["James, S., et al. (2022). RoboGen: Benchmarking large-scale robot learning in simulation. ",(0,o.jsx)(n.em,{children:"arXiv preprint arXiv:2204.02389"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Sadeghi, F., & Levine, S. (2017). CAD2RL: Real single-image flight without a single real image. ",(0,o.jsx)(n.em,{children:"Proceedings of the 1st Annual Conference on Robot Learning"}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"perception-and-navigation",children:"Perception and Navigation"}),"\n",(0,o.jsxs)(n.ol,{start:"17",children:["\n",(0,o.jsxs)(n.li,{children:["Mur-Artal, R., & Tard\xf3s, J. D. (2017). ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras. ",(0,o.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 33(5), 1255-1262."]}),"\n",(0,o.jsxs)(n.li,{children:["Kuipers, B. (2000). The spatial semantic hierarchy. ",(0,o.jsx)(n.em,{children:"Artificial Intelligence"}),", 119(1-2), 59-107."]}),"\n",(0,o.jsxs)(n.li,{children:["Fox, D., et al. (1997). Active Markov localization for mobile robots. ",(0,o.jsx)(n.em,{children:"Robotics and Autonomous Systems"}),", 25(3-4), 195-207."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"vision-language-action-systems",children:"Vision-Language-Action Systems"}),"\n",(0,o.jsxs)(n.ol,{start:"20",children:["\n",(0,o.jsxs)(n.li,{children:["Chen, X., et al. (2021). An empirical study of training end-to-end vision-and-language transformers. ",(0,o.jsx)(n.em,{children:"Proceedings of the IEEE/CVF International Conference on Computer Vision"}),", 10420-10431."]}),"\n",(0,o.jsxs)(n.li,{children:["Blukis, V., et al. (2018). Mapping instructions and visual observations to actions with reinforcement learning. ",(0,o.jsx)(n.em,{children:"Proceedings of the 2018 Conference on Robot Learning"}),", 761-773."]}),"\n",(0,o.jsxs)(n.li,{children:["Hermann, K. M., et al. (2017). Grounded language learning in a simulated 3D world. ",(0,o.jsx)(n.em,{children:"arXiv preprint arXiv:1706.06551"}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"reinforcement-learning-for-robotics",children:"Reinforcement Learning for Robotics"}),"\n",(0,o.jsxs)(n.ol,{start:"23",children:["\n",(0,o.jsxs)(n.li,{children:["Kober, J., et al. (2012). Reinforcement learning in robotics: A survey. ",(0,o.jsx)(n.em,{children:"Robotics Research"}),", 145-164."]}),"\n",(0,o.jsxs)(n.li,{children:["Levine, S., et al. (2016). Learning deep neural network policies with continuous actions and deep Q-learning. ",(0,o.jsx)(n.em,{children:"Proceedings of the 33rd International Conference on Machine Learning"}),", 413-422."]}),"\n",(0,o.jsxs)(n.li,{children:["Pinto, L., & Gupta, A. (2017). Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours. ",(0,o.jsx)(n.em,{children:"Proceedings of the IEEE International Conference on Robotics and Automation"}),", 3406-3413."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"humanoid-robotics",children:"Humanoid Robotics"}),"\n",(0,o.jsxs)(n.ol,{start:"26",children:["\n",(0,o.jsxs)(n.li,{children:["Kajita, S., et al. (2003). Biped walking pattern generation by using preview control of zero-moment point. ",(0,o.jsx)(n.em,{children:"Proceedings of the 2003 IEEE International Conference on Robotics and Automation"}),", 1620-1626."]}),"\n",(0,o.jsxs)(n.li,{children:["Takenaka, T., et al. (2009). Real time pattern generation and optimization for humanoid walking. ",(0,o.jsx)(n.em,{children:"Proceedings of the 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems"}),", 1039-1045."]}),"\n",(0,o.jsxs)(n.li,{children:["Audren, H., et al. (2014). Reactive footstep optimization and control: Application to humanoids. ",(0,o.jsx)(n.em,{children:"Proceedings of the 2014 IEEE-RAS International Conference on Humanoid Robots"}),", 292-299."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"large-language-models-in-robotics",children:"Large Language Models in Robotics"}),"\n",(0,o.jsxs)(n.ol,{start:"29",children:["\n",(0,o.jsxs)(n.li,{children:["Brohan, A., et al. (2022). RVT: Robotic viewpoint tracking for learning complex manipulation from human demonstrations. ",(0,o.jsx)(n.em,{children:"arXiv preprint arXiv:2209.11195"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Huang, W., et al. (2022). Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. ",(0,o.jsx)(n.em,{children:"International Conference on Machine Learning"}),", 9158-9174."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"safety-and-ethics-in-robotics",children:"Safety and Ethics in Robotics"}),"\n",(0,o.jsxs)(n.ol,{start:"31",children:["\n",(0,o.jsxs)(n.li,{children:["Lin, P., Abney, K., & Bekey, G. A. (2012). Robot ethics: Mapping the issues for a mechanized world. ",(0,o.jsx)(n.em,{children:"AI & Society"}),", 27(4), 449-458."]}),"\n",(0,o.jsxs)(n.li,{children:["Winfield, A. F., & Jirotka, M. (2018). Ethical governance is essential to building trust in robotics and artificial intelligence systems. ",(0,o.jsx)(n.em,{children:"Philosophical Transactions of the Royal Society A"}),", 376(2133), 20180085."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,o.jsxs)(n.ol,{start:"33",children:["\n",(0,o.jsxs)(n.li,{children:["OpenAI. (2023). ",(0,o.jsx)(n.em,{children:"GPT-4 Technical Report"}),". OpenAI. ",(0,o.jsx)(n.a,{href:"https://openai.com/research/gpt-4",children:"https://openai.com/research/gpt-4"})]}),"\n",(0,o.jsxs)(n.li,{children:["Google AI. (2023). ",(0,o.jsx)(n.em,{children:"PaLM-E: An Embodied Multimodal Language Model"}),". Google Research. ",(0,o.jsx)(n.a,{href:"https://palm-e.github.io/",children:"https://palm-e.github.io/"})]}),"\n",(0,o.jsxs)(n.li,{children:["NVIDIA. (2023). ",(0,o.jsx)(n.em,{children:"Isaac Lab: NVIDIA's Open-Source Robotics Environment"}),". NVIDIA. ",(0,o.jsx)(n.a,{href:"https://isaac-sim.github.io/",children:"https://isaac-sim.github.io/"})]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Note: This bibliography includes references cited throughout the modules as well as additional resources for further reading. All sources are formatted according to APA style guidelines."})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>r,x:()=>a});var o=i(6540);const s={},t=o.createContext(s);function r(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);