"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[472],{1910(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var t=a(4848),o=a(8453);const i={sidebar_position:7},s="Navigation and Path Planning with Nav2: Advanced Navigation Systems for Humanoid Robots",r={id:"module-3/nav2-planning",title:"Navigation and Path Planning with Nav2: Advanced Navigation Systems for Humanoid Robots",description:"Overview",source:"@site/docs/module-3/nav2-planning.md",sourceDirName:"module-3",slug:"/module-3/nav2-planning",permalink:"/Humanoid-Robotics-Book/docs/module-3/nav2-planning",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Isaac ROS for Accelerated Perception and VSLAM: GPU-Accelerated Robotics Pipelines",permalink:"/Humanoid-Robotics-Book/docs/module-3/isaac-ros"},next:{title:"Sim-to-Real Transfer Concepts and Constraints: Bridging the Reality Gap",permalink:"/Humanoid-Robotics-Book/docs/module-3/sim-to-real"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Navigation2 (Nav2)",id:"introduction-to-navigation2-nav2",level:2},{value:"What is Nav2?",id:"what-is-nav2",level:3},{value:"Nav2 Architecture",id:"nav2-architecture",level:3},{value:"Key Components and Their Functions",id:"key-components-and-their-functions",level:3},{value:"Nav2 Installation and Configuration",id:"nav2-installation-and-configuration",level:2},{value:"System Requirements and Installation",id:"system-requirements-and-installation",level:3},{value:"Basic Configuration for Humanoid Robots",id:"basic-configuration-for-humanoid-robots",level:3},{value:"Humanoid-Specific Costmap Configuration",id:"humanoid-specific-costmap-configuration",level:3},{value:"Global Path Planning for Humanoid Robots",id:"global-path-planning-for-humanoid-robots",level:2},{value:"Global Planner Configuration",id:"global-planner-configuration",level:3},{value:"Path Smoothing for Humanoid Locomotion",id:"path-smoothing-for-humanoid-locomotion",level:3},{value:"Local Path Planning and Control",id:"local-path-planning-and-control",level:2},{value:"Local Planner for Humanoid Robots",id:"local-planner-for-humanoid-robots",level:3},{value:"Humanoid-Specific Controller",id:"humanoid-specific-controller",level:3},{value:"Behavior Trees for Complex Navigation",id:"behavior-trees-for-complex-navigation",level:2},{value:"Humanoid Navigation Behavior Tree",id:"humanoid-navigation-behavior-tree",level:3},{value:"Integration with Isaac ROS and Perception",id:"integration-with-isaac-ros-and-perception",level:2},{value:"Perception-Integrated Navigation",id:"perception-integrated-navigation",level:3},{value:"Advanced Navigation Features",id:"advanced-navigation-features",level:2},{value:"Social Navigation for Humanoid Robots",id:"social-navigation-for-humanoid-robots",level:3},{value:"Adaptive Navigation for Dynamic Environments",id:"adaptive-navigation-for-dynamic-environments",level:3},{value:"Performance Optimization and Real-time Considerations",id:"performance-optimization-and-real-time-considerations",level:2},{value:"Real-time Navigation Optimization",id:"real-time-navigation-optimization",level:3},{value:"Practical Applications in Humanoid Robotics",id:"practical-applications-in-humanoid-robotics",level:2},{value:"Humanoid-Specific Navigation Challenges",id:"humanoid-specific-navigation-challenges",level:3},{value:"Best Practices for Nav2 Configuration",id:"best-practices-for-nav2-configuration",level:2},{value:"Configuration Optimization",id:"configuration-optimization",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function _(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"navigation-and-path-planning-with-nav2-advanced-navigation-systems-for-humanoid-robots",children:"Navigation and Path Planning with Nav2: Advanced Navigation Systems for Humanoid Robots"}),"\n",(0,t.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(e.p,{children:"Navigation and path planning form the cognitive navigation layer of humanoid robotics, enabling robots to move safely and efficiently through complex environments while maintaining balance and avoiding obstacles. The Navigation2 (Nav2) stack provides a comprehensive, flexible, and robust framework for mobile robot navigation that has been adapted for the unique requirements of humanoid robots. Unlike traditional wheeled robots, humanoid robots face distinct challenges in navigation due to their bipedal locomotion, dynamic balance requirements, and human-scale interaction patterns."}),"\n",(0,t.jsx)(e.p,{children:"Nav2's component-based architecture allows for the customization of navigation behaviors to suit humanoid robot characteristics, including specialized planners for bipedal locomotion, balance-aware obstacle avoidance, and social navigation capabilities. The integration of perception data from multiple sensors, including those accelerated by Isaac ROS, enables sophisticated navigation strategies that account for both environmental constraints and the robot's physical limitations."}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this section, you should be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Configure Nav2 for humanoid robot-specific navigation requirements"}),"\n",(0,t.jsx)(e.li,{children:"Implement dynamic path planning for complex humanoid environments"}),"\n",(0,t.jsx)(e.li,{children:"Integrate perception data with navigation systems for obstacle avoidance"}),"\n",(0,t.jsx)(e.li,{children:"Optimize navigation parameters for humanoid robot kinematics and dynamics"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-navigation2-nav2",children:"Introduction to Navigation2 (Nav2)"}),"\n",(0,t.jsx)(e.h3,{id:"what-is-nav2",children:"What is Nav2?"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Navigation2 (Nav2)"})," is the next-generation navigation stack for ROS 2, designed to provide robust, flexible, and configurable navigation capabilities for mobile robots. Key features include:"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Component-Based Architecture"}),": Modular design allowing customization of navigation components"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Behavior Trees"}),": Declarative behavior specification for complex navigation tasks"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Advanced Planning Algorithms"}),": State-of-the-art global and local planners"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Recovery Behaviors"}),": Robust handling of navigation failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simulation Integration"}),": Seamless integration with simulation environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Extensive Plugin System"}),": Support for custom navigation behaviors and algorithms"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"nav2-architecture",children:"Nav2 Architecture"}),"\n",(0,t.jsx)(e.p,{children:"Nav2 follows a modular architecture with specialized components:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-mermaid",children:"graph TB\n    A[Nav2 Stack] --\x3e B[Global Planner]\n    A --\x3e C[Local Planner]\n    A --\x3e D[Controller]\n    A --\x3e E[Recovery Manager]\n    A --\x3e F[Behavior Tree Engine]\n\n    B --\x3e G[A*]\n    B --\x3e H[NavFn]\n    B --\x3e I[Global Planner Plugin]\n    C --\x3e J[DWB]\n    C --\x3e K[Trajectory Rollout]\n    C --\x3e L[Local Planner Plugin]\n    D --\x3e M[Pure Pursuit]\n    D --\x3e N[Follow the Gap]\n    D --\x3e O[Controller Plugin]\n    E --\x3e P[Clear Costmap]\n    E --\x3e Q[Rotate Recovery]\n    E --\x3e R[Recovery Plugin]\n\n    A --\x3e S[Costmap 2D]\n    S --\x3e T[Static Layer]\n    S --\x3e U[Obstacle Layer]\n    S --\x3e V[Inflation Layer]\n    S --\x3e W[Humanoid Layer]\n\n    A --\x3e X[Transform Management]\n    A --\x3e Y[Sensor Integration]\n    A --\x3e Z[Action Interface]\n"})}),"\n",(0,t.jsx)(e.h3,{id:"key-components-and-their-functions",children:"Key Components and Their Functions"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Global Planner"}),": Computes high-level path from start to goal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Local Planner"}),": Executes path while avoiding local obstacles"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Controller"}),": Translates plans into robot commands"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Costmap 2D"}),": Maintains obstacle and cost information"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Recovery Manager"}),": Handles navigation failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Behavior Tree Engine"}),": Orchestrates navigation behaviors"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"nav2-installation-and-configuration",children:"Nav2 Installation and Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"system-requirements-and-installation",children:"System Requirements and Installation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Install Nav2 via apt\nsudo apt update\nsudo apt install ros-humble-navigation2\nsudo apt install ros-humble-nav2-bringup\nsudo apt install ros-humble-nav2-rviz-plugins\n\n# Install additional dependencies\nsudo apt install ros-humble-dwb-core\nsudo apt install ros-humble-nav2-simple-commander\nsudo apt install ros-humble-nav2-behaviors\n"})}),"\n",(0,t.jsx)(e.h3,{id:"basic-configuration-for-humanoid-robots",children:"Basic Configuration for Humanoid Robots"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# config/nav2_params_humanoid.yaml\namcl:\n  ros__parameters:\n    use_sim_time: False\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_footprint"\n    beam_count: 60\n    do_beamskip: False\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: True\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\namcl_map_client:\n  ros__parameters:\n    use_sim_time: False\n\namcl_rclcpp_node:\n  ros__parameters:\n    use_sim_time: False\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: False\n    global_frame: map\n    robot_base_frame: base_footprint\n    odom_topic: /odom\n    bt_loop_duration: 10\n    default_server_timeout: 20\n    # Humanoid-specific behavior tree\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_have_remaining_waypoints_condition_bt_node\n    - nav2_is_path_valid_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transformer_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_navigate_through_poses_action_bt_node\n    - nav2_navigate_to_pose_action_bt_node\n'})}),"\n",(0,t.jsx)(e.h3,{id:"humanoid-specific-costmap-configuration",children:"Humanoid-Specific Costmap Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# config/costmap_humanoid.yaml\nglobal_costmap:\n  global_frame: map\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  transform_tolerance: 0.5\n  width: 40\n  height: 40\n  resolution: 0.05  # 5cm resolution for detailed planning\n  origin_x: -20.0\n  origin_y: -20.0\n  plugins:\n    - {name: static_layer, type: "nav2_costmap_2d::StaticLayer"}\n    - {name: obstacle_layer, type: "nav2_costmap_2d::ObstacleLayer"}\n    - {name: inflation_layer, type: "nav2_costmap_2d::InflationLayer"}\n    - {name: humanoid_layer, type: "nav2_costmap_2d::HumanoidLayer"}  # Custom layer\n\n  static_layer:\n    map_topic: /map\n    transform_tolerance: 0.5\n    max_publish_frequency: 0.1\n\n  obstacle_layer:\n    enabled: True\n    observation_sources: scan\n    scan:\n      topic: /scan\n      max_obstacle_height: 2.0  # Humanoid can step over low obstacles\n      clearing: True\n      marking: True\n      data_type: "LaserScan"\n      raytrace_max_range: 3.0\n      raytrace_min_range: 0.0\n      obstacle_max_range: 2.5\n      obstacle_min_range: 0.0\n\n  inflation_layer:\n    enabled: True\n    cost_scaling_factor: 3.0  # Increased for humanoid safety\n    inflation_radius: 0.6     # Larger safety margin for bipedal robot\n\n  humanoid_layer:\n    enabled: True\n    step_height: 0.15         # Maximum step height humanoid can handle\n    step_width: 0.3          # Minimum step width for stable walking\n    balance_margin: 0.2      # Extra margin for balance considerations\n\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_footprint\n  update_frequency: 10.0\n  publish_frequency: 5.0\n  transform_tolerance: 0.5\n  width: 6.0\n  height: 6.0\n  resolution: 0.05\n  plugins:\n    - {name: obstacle_layer, type: "nav2_costmap_2d::ObstacleLayer"}\n    - {name: voxel_layer, type: "nav2_costmap_2d::VoxelLayer"}\n    - {name: inflation_layer, type: "nav2_costmap_2d::InflationLayer"}\n\n  obstacle_layer:\n    enabled: True\n    observation_sources: scan\n    scan:\n      topic: /scan\n      max_obstacle_height: 2.0\n      clearing: True\n      marking: True\n      data_type: "LaserScan"\n      raytrace_max_range: 3.0\n      raytrace_min_range: 0.0\n      obstacle_max_range: 2.5\n      obstacle_min_range: 0.0\n\n  voxel_layer:\n    enabled: True\n    publish_voxel_map: False\n    origin_z: 0.0\n    z_resolution: 0.2\n    z_voxels: 10\n    max_obstacle_height: 2.0\n    mark_threshold: 0\n    observation_sources: scan\n    scan:\n      topic: /scan\n      max_obstacle_height: 2.0\n      clearing: True\n      marking: True\n      data_type: "LaserScan"\n      raytrace_max_range: 3.0\n      raytrace_min_range: 0.0\n      obstacle_max_range: 2.5\n      obstacle_min_range: 0.0\n\n  inflation_layer:\n    enabled: True\n    cost_scaling_factor: 5.0  # Higher for local planning\n    inflation_radius: 0.5\n'})}),"\n",(0,t.jsx)(e.h2,{id:"global-path-planning-for-humanoid-robots",children:"Global Path Planning for Humanoid Robots"}),"\n",(0,t.jsx)(e.h3,{id:"global-planner-configuration",children:"Global Planner Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom sensor_msgs.msg import LaserScan\nfrom tf2_ros import TransformListener, Buffer\nimport numpy as np\n\nclass HumanoidGlobalPlanner:\n    def __init__(self, node):\n        self.node = node\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, node)\n\n        # Global planner parameters for humanoid\n        self.step_size = 0.3  # Maximum step size for humanoid\n        self.turn_radius = 0.4  # Minimum turning radius\n        self.balance_margin = 0.2  # Safety margin for balance\n\n        # Initialize path planners\n        self.a_star_planner = AStarPlanner()\n        self.hybrid_astar_planner = HybridAStarPlanner()\n        self.visibility_graph_planner = VisibilityGraphPlanner()\n\n    def plan_path(self, start_pose, goal_pose, costmap):\n        """Plan path considering humanoid constraints"""\n        # Convert poses to costmap coordinates\n        start_coords = self.pose_to_costmap_coords(start_pose, costmap)\n        goal_coords = self.pose_to_costmap_coords(goal_pose, costmap)\n\n        # Plan path using humanoid-aware algorithm\n        path = self.plan_humanoid_path(start_coords, goal_coords, costmap)\n\n        # Smooth path for humanoid locomotion\n        smoothed_path = self.smooth_humanoid_path(path)\n\n        # Convert back to PoseStamped messages\n        pose_path = self.path_to_pose_stamped(smoothed_path, costmap)\n\n        return pose_path\n\n    def plan_humanoid_path(self, start, goal, costmap):\n        """Plan path considering humanoid locomotion constraints"""\n        # Check if direct path is feasible\n        direct_path = self.check_direct_path_feasibility(start, goal, costmap)\n\n        if direct_path:\n            return [start, goal]\n\n        # Use A* with humanoid constraints\n        path = self.a_star_planner.plan_with_constraints(\n            start, goal, costmap, self.get_humanoid_constraints()\n        )\n\n        return path\n\n    def get_humanoid_constraints(self):\n        """Define constraints specific to humanoid locomotion"""\n        return {\n            \'max_step_size\': self.step_size,\n            \'min_turn_radius\': self.turn_radius,\n            \'balance_margin\': self.balance_margin,\n            \'step_height_tolerance\': 0.15,  # Maximum step height\n            \'footprint_radius\': 0.15       # Humanoid foot print\n        }\n\n    def check_direct_path_feasibility(self, start, goal, costmap):\n        """Check if direct path is feasible for humanoid"""\n        # Calculate path points\n        path_points = self.discretize_path(start, goal, resolution=0.1)\n\n        # Check each point for feasibility\n        for point in path_points:\n            if not self.is_point_feasible(point, costmap):\n                return False\n\n        # Check path width for humanoid\n        if not self.is_path_width_sufficient(start, goal, costmap):\n            return False\n\n        return True\n\n    def is_point_feasible(self, point, costmap):\n        """Check if a point is feasible for humanoid"""\n        x, y = point\n\n        # Check costmap value\n        cost = self.get_costmap_value(x, y, costmap)\n        if cost >= 254:  # Occupied\n            return False\n\n        # Check balance constraints\n        if not self.check_balance_feasibility(point, costmap):\n            return False\n\n        return True\n\n    def check_balance_feasibility(self, point, costmap):\n        """Check if point allows for stable balance"""\n        # Check surrounding area for balance support\n        balance_radius = self.balance_margin\n        for dx in np.arange(-balance_radius, balance_radius, costmap.resolution):\n            for dy in np.arange(-balance_radius, balance_radius, costmap.resolution):\n                test_x = point[0] + dx\n                test_y = point[1] + dy\n\n                if self.is_in_costmap_bounds(test_x, test_y, costmap):\n                    cost = self.get_costmap_value(test_x, test_y, costmap)\n                    if cost >= 200:  # High cost area\n                        return False\n\n        return True\n\nclass AStarPlanner:\n    def __init__(self):\n        self.max_iterations = 10000\n        self.step_size = 0.3\n\n    def plan_with_constraints(self, start, goal, costmap, constraints):\n        """A* planning with humanoid constraints"""\n        import heapq\n\n        # Initialize open and closed sets\n        open_set = [(0, start)]\n        came_from = {}\n        g_score = {start: 0}\n        f_score = {start: self.heuristic(start, goal)}\n\n        while open_set:\n            current = heapq.heappop(open_set)[1]\n\n            if self.distance(current, goal) < 0.5:  # Goal reached\n                return self.reconstruct_path(came_from, current)\n\n            # Get neighbors considering humanoid constraints\n            neighbors = self.get_humanoid_neighbors(current, costmap, constraints)\n\n            for neighbor in neighbors:\n                tentative_g_score = g_score[current] + self.distance(current, neighbor)\n\n                if tentative_g_score < g_score.get(neighbor, float(\'inf\')):\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, goal)\n\n                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def get_humanoid_neighbors(self, point, costmap, constraints):\n        """Get valid neighbors considering humanoid constraints"""\n        neighbors = []\n        max_step = constraints[\'max_step_size\']\n\n        # Generate potential neighbors in all directions\n        for angle in np.linspace(0, 2*np.pi, 16):  # 16 directions\n            dx = max_step * np.cos(angle)\n            dy = max_step * np.sin(angle)\n            neighbor = (point[0] + dx, point[1] + dy)\n\n            # Check if neighbor is valid\n            if (self.is_valid_neighbor(neighbor, costmap, constraints) and\n                self.is_step_feasible(point, neighbor, costmap, constraints)):\n                neighbors.append(neighbor)\n\n        return neighbors\n\n    def is_step_feasible(self, start, end, costmap, constraints):\n        """Check if step from start to end is feasible for humanoid"""\n        # Check maximum step size\n        step_distance = self.distance(start, end)\n        if step_distance > constraints[\'max_step_size\']:\n            return False\n\n        # Check step height constraints (if height data available)\n        if hasattr(costmap, \'height_data\'):\n            height_diff = abs(costmap.height_data[end] - costmap.height_data[start])\n            if height_diff > constraints[\'step_height_tolerance\']:\n                return False\n\n        # Check path between start and end\n        path_points = self.discretize_path(start, end, resolution=0.1)\n        for point in path_points:\n            if not self.is_valid_neighbor(point, costmap, constraints):\n                return False\n\n        return True\n'})}),"\n",(0,t.jsx)(e.h3,{id:"path-smoothing-for-humanoid-locomotion",children:"Path Smoothing for Humanoid Locomotion"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class PathSmoother:\n    def __init__(self):\n        self.smoothing_iterations = 100\n        self.smoothing_weight = 0.1\n        self.obstacle_weight = 0.5\n        self.smoothness_weight = 0.4\n\n    def smooth_humanoid_path(self, path):\n        """Smooth path for humanoid locomotion"""\n        if len(path) < 3:\n            return path\n\n        smoothed_path = path.copy()\n\n        for _ in range(self.smoothing_iterations):\n            improved = False\n            for i in range(1, len(smoothed_path) - 1):\n                old_point = smoothed_path[i]\n                new_point = self.calculate_smoothed_point(\n                    smoothed_path, i\n                )\n\n                if self.is_smoothing_improvement(old_point, new_point, smoothed_path, i):\n                    smoothed_path[i] = new_point\n                    improved = True\n\n            if not improved:\n                break\n\n        return smoothed_path\n\n    def calculate_smoothed_point(self, path, index):\n        """Calculate smoothed point using neighboring points"""\n        prev_point = path[index - 1]\n        next_point = path[index + 1]\n\n        # Average of neighboring points\n        smoothed_x = (prev_point[0] + next_point[0]) / 2\n        smoothed_y = (prev_point[1] + next_point[1]) / 2\n\n        return (smoothed_x, smoothed_y)\n\n    def is_smoothing_improvement(self, old_point, new_point, path, index):\n        """Check if smoothing improves path quality"""\n        # Check if new point is valid\n        if not self.is_point_valid(new_point, path, index):\n            return False\n\n        # Calculate path quality metrics\n        old_quality = self.calculate_path_quality_at_point(path, index, old_point)\n        new_quality = self.calculate_path_quality_at_point(path, index, new_point)\n\n        return new_quality < old_quality\n\n    def calculate_path_quality_at_point(self, path, index, point):\n        """Calculate quality of path at specific point"""\n        quality = 0\n\n        # Distance to original path (should stay close)\n        original_point = path[index]\n        quality += self.smoothing_weight * self.distance(original_point, point)\n\n        # Obstacle proximity penalty\n        obstacle_penalty = self.calculate_obstacle_penalty(point, path)\n        quality += self.obstacle_weight * obstacle_penalty\n\n        # Smoothness penalty\n        smoothness_penalty = self.calculate_smoothness_penalty(path, index, point)\n        quality += self.smoothness_weight * smoothness_penalty\n\n        return quality\n\n    def calculate_obstacle_penalty(self, point, path):\n        """Calculate penalty for proximity to obstacles"""\n        # This would check distance to nearest obstacles\n        # Higher penalty for closer obstacles\n        pass\n\n    def calculate_smoothness_penalty(self, path, index, point):\n        """Calculate penalty for path smoothness"""\n        if index == 0 or index == len(path) - 1:\n            return 0\n\n        prev_point = path[index - 1] if index > 0 else point\n        next_point = path[index + 1] if index < len(path) - 1 else point\n\n        # Calculate angles to measure smoothness\n        angle1 = self.calculate_angle(prev_point, point, next_point)\n        # Smoother paths have angles closer to 180 degrees (straight line)\n\n        return abs(np.pi - angle1)  # Penalty for sharp turns\n'})}),"\n",(0,t.jsx)(e.h2,{id:"local-path-planning-and-control",children:"Local Path Planning and Control"}),"\n",(0,t.jsx)(e.h3,{id:"local-planner-for-humanoid-robots",children:"Local Planner for Humanoid Robots"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class HumanoidLocalPlanner:\n    def __init__(self, node):\n        self.node = node\n        self.robot_radius = 0.3  # Humanoid robot radius\n        self.max_vel_x = 0.3     # Maximum forward velocity\n        self.max_vel_theta = 0.5 # Maximum angular velocity\n        self.min_vel_x = 0.05    # Minimum forward velocity\n        self.controller_frequency = 10.0\n\n        # Initialize local planner\n        self.dwb_planner = DWBPlanner()\n        self.trajectory_generator = TrajectoryGenerator()\n        self.obstacle_avoider = ObstacleAvoider()\n\n    def plan_local_path(self, global_path, current_pose, costmap):\n        """Plan local path with obstacle avoidance"""\n        # Get current goal from global path\n        current_goal = self.get_current_goal(global_path, current_pose)\n\n        # Generate feasible trajectories\n        trajectories = self.generate_feasible_trajectories(\n            current_pose, current_goal, costmap\n        )\n\n        # Evaluate trajectories\n        best_trajectory = self.evaluate_trajectories(\n            trajectories, current_pose, current_goal, costmap\n        )\n\n        return best_trajectory\n\n    def generate_feasible_trajectories(self, current_pose, goal, costmap):\n        """Generate feasible trajectories for humanoid"""\n        trajectories = []\n\n        # Sample different velocity combinations\n        for vel_x in np.linspace(self.min_vel_x, self.max_vel_x, 5):\n            for vel_theta in np.linspace(-self.max_vel_theta, self.max_vel_theta, 5):\n                trajectory = self.trajectory_generator.generate_trajectory(\n                    current_pose, vel_x, vel_theta, self.controller_frequency\n                )\n\n                # Check trajectory feasibility\n                if self.is_trajectory_feasible(trajectory, costmap):\n                    trajectories.append(trajectory)\n\n        return trajectories\n\n    def is_trajectory_feasible(self, trajectory, costmap):\n        """Check if trajectory is feasible for humanoid"""\n        for pose in trajectory:\n            # Check if pose is in collision\n            if self.is_pose_in_collision(pose, costmap):\n                return False\n\n            # Check balance constraints\n            if not self.check_balance_constraints(pose, trajectory):\n                return False\n\n        return True\n\n    def is_pose_in_collision(self, pose, costmap):\n        """Check if pose is in collision with obstacles"""\n        # Convert pose to costmap coordinates\n        x, y = pose.position.x, pose.position.y\n        costmap_x, costmap_y = self.world_to_costmap_coords(x, y, costmap)\n\n        # Check costmap value\n        if (0 <= costmap_x < costmap.info.width and\n            0 <= costmap_y < costmap.info.height):\n            cost_index = costmap_y * costmap.info.width + costmap_x\n            cost = costmap.data[cost_index]\n            return cost >= 254  # Occupied space\n        else:\n            return True  # Outside costmap bounds\n\n    def check_balance_constraints(self, pose, trajectory):\n        """Check if pose maintains humanoid balance"""\n        # Check if pose is within balance constraints\n        # This would consider Center of Mass position, ZMP, etc.\n        pass\n\n    def evaluate_trajectories(self, trajectories, current_pose, goal, costmap):\n        """Evaluate and select best trajectory"""\n        best_trajectory = None\n        best_score = float(\'-inf\')\n\n        for trajectory in trajectories:\n            score = self.evaluate_trajectory(trajectory, current_pose, goal, costmap)\n            if score > best_score:\n                best_score = score\n                best_trajectory = trajectory\n\n        return best_trajectory\n\n    def evaluate_trajectory(self, trajectory, current_pose, goal, costmap):\n        """Evaluate trajectory based on multiple criteria"""\n        # Calculate multiple scores\n        goal_score = self.calculate_goal_score(trajectory, goal)\n        obstacle_score = self.calculate_obstacle_score(trajectory, costmap)\n        smoothness_score = self.calculate_smoothness_score(trajectory)\n        velocity_score = self.calculate_velocity_score(trajectory)\n\n        # Weighted combination\n        total_score = (\n            0.4 * goal_score +\n            0.3 * obstacle_score +\n            0.2 * smoothness_score +\n            0.1 * velocity_score\n        )\n\n        return total_score\n\n    def calculate_goal_score(self, trajectory, goal):\n        """Calculate score based on goal proximity"""\n        if not trajectory:\n            return 0.0\n\n        final_pose = trajectory[-1]\n        distance_to_goal = self.distance_pose_to_point(final_pose, goal)\n\n        # Inverse relationship: closer is better\n        return 1.0 / (1.0 + distance_to_goal)\n\n    def calculate_obstacle_score(self, trajectory, costmap):\n        """Calculate score based on obstacle proximity"""\n        min_distance_to_obstacle = float(\'inf\')\n\n        for pose in trajectory:\n            distance = self.distance_to_nearest_obstacle(pose, costmap)\n            min_distance_to_obstacle = min(min_distance_to_obstacle, distance)\n\n        # Higher score for trajectories farther from obstacles\n        return min_distance_to_obstacle\n'})}),"\n",(0,t.jsx)(e.h3,{id:"humanoid-specific-controller",children:"Humanoid-Specific Controller"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class HumanoidController:\n    def __init__(self):\n        # Humanoid-specific control parameters\n        self.step_height = 0.1   # Height of foot during step\n        self.step_length = 0.3   # Length of each step\n        self.step_duration = 1.0 # Time for each step\n        self.balance_margin = 0.1 # Balance safety margin\n\n        # PID controllers for humanoid motion\n        self.x_pid = PIDController(kp=2.0, ki=0.1, kd=0.05)\n        self.y_pid = PIDController(kp=2.0, ki=0.1, kd=0.05)\n        self.theta_pid = PIDController(kp=3.0, ki=0.1, kd=0.1)\n\n        # Balance control\n        self.balance_controller = BalanceController()\n        self.zmp_controller = ZMPController()\n\n    def follow_path(self, path, robot_state):\n        """Follow path with humanoid-specific control"""\n        if not path.poses:\n            return None\n\n        # Get next waypoint\n        next_waypoint = self.get_next_waypoint(path, robot_state)\n\n        # Calculate control commands\n        control_cmd = self.calculate_control_commands(\n            robot_state, next_waypoint\n        )\n\n        # Apply balance control\n        balance_cmd = self.balance_controller.calculate_balance_command(\n            robot_state, control_cmd\n        )\n\n        # Combine control commands\n        final_cmd = self.combine_commands(control_cmd, balance_cmd)\n\n        return final_cmd\n\n    def calculate_control_commands(self, robot_state, waypoint):\n        """Calculate control commands to reach waypoint"""\n        # Calculate errors\n        error_x = waypoint.pose.position.x - robot_state.position.x\n        error_y = waypoint.pose.position.y - robot_state.position.y\n        error_theta = self.normalize_angle(\n            self.calculate_yaw(waypoint.pose) - robot_state.yaw\n        )\n\n        # Apply PID control\n        cmd_x = self.x_pid.update(error_x)\n        cmd_y = self.y_pid.update(error_y)\n        cmd_theta = self.theta_pid.update(error_theta)\n\n        # Limit commands based on humanoid capabilities\n        cmd_x = self.limit_velocity(cmd_x, self.max_vel_x)\n        cmd_y = self.limit_velocity(cmd_y, self.max_vel_y)\n        cmd_theta = self.limit_velocity(cmd_theta, self.max_vel_theta)\n\n        return {\n            \'linear_x\': cmd_x,\n            \'linear_y\': cmd_y,\n            \'angular_z\': cmd_theta\n        }\n\n    def calculate_yaw(self, pose):\n        """Calculate yaw from pose orientation"""\n        import math\n        # Convert quaternion to yaw\n        siny_cosp = 2 * (pose.orientation.w * pose.orientation.z +\n                         pose.orientation.x * pose.orientation.y)\n        cosy_cosp = 1 - 2 * (pose.orientation.y * pose.orientation.y +\n                            pose.orientation.z * pose.orientation.z)\n        return math.atan2(siny_cosp, cosy_cosp)\n\n    def normalize_angle(self, angle):\n        """Normalize angle to [-\u03c0, \u03c0] range"""\n        while angle > np.pi:\n            angle -= 2 * np.pi\n        while angle < -np.pi:\n            angle += 2 * np.pi\n        return angle\n\n    def limit_velocity(self, vel, max_vel):\n        """Limit velocity to maximum value"""\n        return max(min(vel, max_vel), -max_vel)\n\n    def combine_commands(self, motion_cmd, balance_cmd):\n        """Combine motion and balance commands"""\n        # This would combine motion commands with balance corrections\n        # for stable humanoid locomotion\n        combined_cmd = motion_cmd.copy()\n\n        # Apply balance corrections\n        combined_cmd[\'linear_x\'] += balance_cmd.get(\'correction_x\', 0)\n        combined_cmd[\'linear_y\'] += balance_cmd.get(\'correction_y\', 0)\n        combined_cmd[\'angular_z\'] += balance_cmd.get(\'correction_theta\', 0)\n\n        return combined_cmd\n\nclass PIDController:\n    def __init__(self, kp=1.0, ki=0.0, kd=0.0):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.prev_error = 0.0\n        self.integral = 0.0\n\n    def update(self, error, dt=0.1):\n        """Update PID controller with new error"""\n        # Proportional term\n        p_term = self.kp * error\n\n        # Integral term\n        self.integral += error * dt\n        i_term = self.ki * self.integral\n\n        # Derivative term\n        derivative = (error - self.prev_error) / dt if dt > 0 else 0\n        d_term = self.kd * derivative\n\n        self.prev_error = error\n\n        return p_term + i_term + d_term\n\nclass BalanceController:\n    def __init__(self):\n        self.zmp_controller = ZMPController()\n        self.com_controller = COMController()\n        self.ankle_controller = AnkleController()\n\n    def calculate_balance_command(self, robot_state, motion_cmd):\n        """Calculate balance commands to maintain stability"""\n        # Calculate desired Zero Moment Point (ZMP)\n        desired_zmp = self.zmp_controller.calculate_desired_zmp(\n            motion_cmd, robot_state\n        )\n\n        # Calculate Center of Mass (CoM) trajectory\n        com_trajectory = self.com_controller.calculate_com_trajectory(\n            desired_zmp, robot_state\n        )\n\n        # Calculate ankle torques for balance\n        ankle_torques = self.ankle_controller.calculate_ankle_torques(\n            com_trajectory, robot_state\n        )\n\n        return {\n            \'zmp_correction\': desired_zmp,\n            \'com_trajectory\': com_trajectory,\n            \'ankle_torques\': ankle_torques\n        }\n'})}),"\n",(0,t.jsx)(e.h2,{id:"behavior-trees-for-complex-navigation",children:"Behavior Trees for Complex Navigation"}),"\n",(0,t.jsx)(e.h3,{id:"humanoid-navigation-behavior-tree",children:"Humanoid Navigation Behavior Tree"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import py_trees\nfrom py_trees.behaviours import *\nfrom py_trees.composites import *\nfrom py_trees.decorators import *\nfrom py_trees.blackboard import Blackboard\n\nclass HumanoidNavigationBehaviorTree:\n    def __init__(self):\n        self.setup_blackboard()\n        self.root = self.create_behavior_tree()\n\n    def setup_blackboard(self):\n        """Setup blackboard for navigation state"""\n        Blackboard().set("robot_pose", None)\n        Blackboard().set("goal_pose", None)\n        Blackboard().set("navigation_state", "IDLE")\n        Blackboard().set("current_path", None)\n        Blackboard().set("obstacle_detected", False)\n        Blackboard().set("balance_stable", True)\n\n    def create_behavior_tree(self):\n        """Create navigation behavior tree for humanoid"""\n        # Main navigation sequence\n        main_sequence = Sequence(name="Main Navigation")\n\n        # Goal checking\n        has_goal = py_trees.blackboard.CheckBlackboardVariable(\n            name="Has Goal",\n            variable_name="goal_pose",\n            expected_value=None,\n            comparison_operator=lambda x, y: x is not y\n        )\n\n        # Localization check\n        is_localized = IsLocalized(name="Is Localized")\n\n        # Navigation task\n        navigate = NavigateToPose(name="Navigate to Pose")\n\n        # Recovery sequence\n        recovery_sequence = Sequence(name="Recovery Sequence")\n        clear_costmaps = ClearCostmap(name="Clear Costmaps")\n        rotate_recovery = RotateRecovery(name="Rotate Recovery")\n\n        recovery_sequence.add_children([clear_costmaps, rotate_recovery])\n\n        # Main sequence\n        main_sequence.add_children([\n            has_goal,\n            is_localized,\n            navigate\n        ])\n\n        # Recovery decorator\n        recovery_with_fallback = py_trees.composites.Selector(name="Navigate with Recovery")\n        recovery_with_fallback.add_children([main_sequence, recovery_sequence])\n\n        return recovery_with_fallback\n\nclass IsLocalized(py_trees.behaviour.Behaviour):\n    def __init__(self, name="Is Localized"):\n        super(IsLocalized, self).__init__(name)\n        self.pose_subscriber = None\n\n    def setup(self, **kwargs):\n        """Setup ROS subscriber"""\n        try:\n            self.node = kwargs[\'node\']\n            self.pose_subscriber = self.node.create_subscription(\n                PoseWithCovarianceStamped,\n                \'/amcl_pose\',\n                self.pose_callback,\n                10\n            )\n        except Exception as e:\n            self.logger.error(f"Failed to setup IsLocalized: {str(e)}")\n\n    def pose_callback(self, msg):\n        """Update localization status"""\n        # Check if pose covariance is low (well localized)\n        covariance_sum = sum(msg.pose.covariance)\n        is_localized = covariance_sum < 1.0  # Threshold for localization\n        Blackboard().set("is_localized", is_localized)\n\n    def update(self):\n        """Update behavior status"""\n        is_localized = Blackboard().get("is_localized", False)\n\n        if is_localized:\n            return py_trees.common.Status.SUCCESS\n        else:\n            return py_trees.common.Status.FAILURE\n\nclass NavigateToPose(py_trees.behaviour.Behaviour):\n    def __init__(self, name="Navigate to Pose"):\n        super(NavigateToPose, self).__init__(name)\n        self.nav_client = None\n\n    def setup(self, **kwargs):\n        """Setup navigation client"""\n        try:\n            self.node = kwargs[\'node\']\n            self.nav_client = ActionClient(\n                self.node,\n                NavigateToPose,\n                \'navigate_to_pose\'\n            )\n        except Exception as e:\n            self.logger.error(f"Failed to setup NavigateToPose: {str(e)}")\n\n    def update(self):\n        """Update navigation behavior"""\n        goal_pose = Blackboard().get("goal_pose")\n\n        if goal_pose is None:\n            return py_trees.common.Status.FAILURE\n\n        if not self.nav_client.server_is_ready():\n            return py_trees.common.Status.RUNNING\n\n        # Send navigation goal\n        goal = NavigateToPose.Goal()\n        goal.pose = goal_pose\n\n        future = self.nav_client.send_goal_async(goal)\n        future.add_done_callback(self.goal_response_callback)\n\n        return py_trees.common.Status.RUNNING\n\n    def goal_response_callback(self, future):\n        """Handle goal response"""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            Blackboard().set("navigation_result", "REJECTED")\n            return\n\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self.get_result_callback)\n\n    def get_result_callback(self, future):\n        """Handle navigation result"""\n        result = future.result().result\n        Blackboard().set("navigation_result", result)\n\nclass ClearCostmap(py_trees.behaviour.Behaviour):\n    def __init__(self, name="Clear Costmaps"):\n        super(ClearCostmap, self).__init__(name)\n        self.clear_costmap_client = None\n\n    def setup(self, **kwargs):\n        """Setup clear costmap service client"""\n        try:\n            self.node = kwargs[\'node\']\n            self.clear_costmap_client = self.node.create_client(\n                ClearEntireCostmap,\n                \'/global_costmap/clear_entirely_global_costmap\'\n            )\n        except Exception as e:\n            self.logger.error(f"Failed to setup ClearCostmap: {str(e)}")\n\n    def update(self):\n        """Update clear costmap behavior"""\n        if not self.clear_costmap_client.service_is_ready():\n            return py_trees.common.Status.RUNNING\n\n        # Send clear costmap request\n        request = ClearEntireCostmap.Request()\n        future = self.clear_costmap_client.call_async(request)\n        future.add_done_callback(self.clear_response_callback)\n\n        return py_trees.common.Status.RUNNING\n\n    def clear_response_callback(self, future):\n        """Handle clear costmap response"""\n        response = future.result()\n        if response is not None:\n            Blackboard().set("costmaps_cleared", True)\n        else:\n            Blackboard().set("costmaps_cleared", False)\n'})}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-isaac-ros-and-perception",children:"Integration with Isaac ROS and Perception"}),"\n",(0,t.jsx)(e.h3,{id:"perception-integrated-navigation",children:"Perception-Integrated Navigation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class PerceptionIntegratedNavigation:\n    def __init__(self, node):\n        self.node = node\n        self.nav2_client = None\n        self.isaac_ros_nodes = None\n        self.perception_fusion = PerceptionFusion()\n\n        # Initialize navigation components\n        self.global_planner = HumanoidGlobalPlanner(node)\n        self.local_planner = HumanoidLocalPlanner(node)\n        self.controller = HumanoidController()\n\n        # Perception integration\n        self.human_detector = HumanDetector()\n        self.obstacle_detector = ObstacleDetector()\n        self.floor_plane_detector = FloorPlaneDetector()\n\n    def navigate_with_perception(self, goal_pose, sensor_data):\n        """Navigate using integrated perception data"""\n        # Process sensor data\n        perception_results = self.process_perception_data(sensor_data)\n\n        # Update costmaps with perception data\n        updated_costmap = self.update_costmap_with_perception(\n            perception_results\n        )\n\n        # Plan path considering perception results\n        path = self.global_planner.plan_path(\n            self.get_current_pose(),\n            goal_pose,\n            updated_costmap\n        )\n\n        # Execute navigation with local planning\n        success = self.execute_navigation_with_perception(\n            path, perception_results\n        )\n\n        return success\n\n    def process_perception_data(self, sensor_data):\n        """Process perception data from Isaac ROS nodes"""\n        results = {}\n\n        # Process human detection\n        if \'image\' in sensor_data and \'depth\' in sensor_data:\n            humans = self.human_detector.detect(\n                sensor_data[\'image\'],\n                sensor_data[\'depth\']\n            )\n            results[\'humans\'] = humans\n\n        # Process obstacle detection\n        if \'pointcloud\' in sensor_data:\n            obstacles = self.obstacle_detector.detect(\n                sensor_data[\'pointcloud\']\n            )\n            results[\'obstacles\'] = obstacles\n\n        # Process floor plane\n        if \'pointcloud\' in sensor_data:\n            floor_plane = self.floor_plane_detector.detect(\n                sensor_data[\'pointcloud\']\n            )\n            results[\'floor_plane\'] = floor_plane\n\n        # Integrate with Isaac ROS results\n        if \'isaac_detections\' in sensor_data:\n            results[\'detections\'] = sensor_data[\'isaac_detections\']\n\n        return results\n\n    def update_costmap_with_perception(self, perception_results):\n        """Update costmap with perception information"""\n        # Get current costmap\n        current_costmap = self.get_current_costmap()\n\n        # Update with human positions (social navigation)\n        if \'humans\' in perception_results:\n            self.update_costmap_with_humans(\n                current_costmap,\n                perception_results[\'humans\']\n            )\n\n        # Update with dynamic obstacles\n        if \'obstacles\' in perception_results:\n            self.update_costmap_with_obstacles(\n                current_costmap,\n                perception_results[\'obstacles\']\n            )\n\n        # Update with floor information\n        if \'floor_plane\' in perception_results:\n            self.update_costmap_with_floor(\n                current_costmap,\n                perception_results[\'floor_plane\']\n            )\n\n        return current_costmap\n\n    def update_costmap_with_humans(self, costmap, humans):\n        """Update costmap with human positions for social navigation"""\n        for human in humans:\n            if human[\'confidence\'] > 0.7:  # High confidence detections\n                # Calculate human position in costmap coordinates\n                human_x, human_y = human[\'position_3d\'][:2]\n                costmap_x, costmap_y = self.world_to_costmap_coords(\n                    human_x, human_y, costmap\n                )\n\n                # Apply social force model around human\n                self.apply_social_force_to_costmap(\n                    costmap, costmap_x, costmap_y,\n                    radius=1.0, strength=200\n                )\n\n    def apply_social_force_to_costmap(self, costmap, center_x, center_y, radius, strength):\n        """Apply social force model to costmap"""\n        # Calculate affected area\n        start_x = max(0, int(center_x - radius / costmap.resolution))\n        end_x = min(costmap.info.width, int(center_x + radius / costmap.resolution))\n        start_y = max(0, int(center_y - radius / costmap.resolution))\n        end_y = min(costmap.info.height, int(center_y + radius / costmap.resolution))\n\n        # Apply force based on distance from center\n        for x in range(start_x, end_x):\n            for y in range(start_y, end_y):\n                world_x, world_y = self.costmap_to_world_coords(x, y, costmap)\n                distance = np.sqrt(\n                    (world_x - center_x * costmap.resolution)**2 +\n                    (world_y - center_y * costmap.resolution)**2\n                )\n\n                if distance <= radius:\n                    force = strength * (1 - distance / radius)\n                    costmap_index = y * costmap.info.width + x\n                    current_cost = costmap.data[costmap_index]\n                    new_cost = min(254, int(current_cost + force))\n                    costmap.data[costmap_index] = new_cost\n\n    def execute_navigation_with_perception(self, path, perception_results):\n        """Execute navigation while monitoring perception data"""\n        path_following = True\n        current_waypoint = 0\n\n        while path_following and current_waypoint < len(path.poses):\n            # Get current robot state\n            current_pose = self.get_current_pose()\n            current_state = self.get_robot_state()\n\n            # Check for dynamic obstacles\n            if self.detect_dynamic_obstacles(perception_results):\n                # Replan path avoiding dynamic obstacles\n                new_path = self.replan_with_dynamic_obstacles(\n                    current_pose,\n                    path.poses[current_waypoint:],\n                    perception_results\n                )\n                path = new_path\n                current_waypoint = 0\n\n            # Check for humans (social navigation)\n            if self.detect_close_humans(perception_results):\n                # Apply social navigation behaviors\n                self.apply_social_navigation(current_pose, perception_results)\n\n            # Follow current path segment\n            waypoint_reached = self.follow_path_to_waypoint(\n                path.poses[current_waypoint],\n                current_pose,\n                current_state\n            )\n\n            if waypoint_reached:\n                current_waypoint += 1\n\n            # Check if navigation should continue\n            path_following = self.should_continue_navigation(\n                current_pose,\n                path.poses[-1],\n                current_state\n            )\n\n        return current_waypoint >= len(path.poses)\n\n    def detect_dynamic_obstacles(self, perception_results):\n        """Detect dynamic obstacles that require replanning"""\n        if \'obstacles\' not in perception_results:\n            return False\n\n        # Check if obstacles are moving toward robot path\n        for obstacle in perception_results[\'obstacles\']:\n            if obstacle.get(\'velocity\', 0) > 0.1:  # Moving faster than 0.1 m/s\n                return True\n\n        return False\n\n    def replan_with_dynamic_obstacles(self, current_pose, remaining_path, perception_results):\n        """Replan path considering dynamic obstacles"""\n        # This would implement dynamic path replanning\n        # considering moving obstacles and their predicted paths\n        pass\n\n    def apply_social_navigation(self, current_pose, perception_results):\n        """Apply social navigation behaviors when humans are detected"""\n        # This would implement social navigation algorithms\n        # like ORCA (Optimal Reciprocal Collision Avoidance)\n        # or other human-aware navigation strategies\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"advanced-navigation-features",children:"Advanced Navigation Features"}),"\n",(0,t.jsx)(e.h3,{id:"social-navigation-for-humanoid-robots",children:"Social Navigation for Humanoid Robots"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class SocialNavigation:\n    def __init__(self):\n        self.social_force_model = SocialForceModel()\n        self.personal_space_radius = 1.0  # meters\n        self.comfort_zone_radius = 0.5    # meters\n        self.anticipation_time = 2.0      # seconds\n\n    def plan_social_path(self, start, goal, humans, static_obstacles):\n        """Plan path considering social interactions"""\n        # Calculate social forces from humans\n        social_forces = self.calculate_social_forces(start, humans)\n\n        # Plan path with social cost\n        path = self.plan_path_with_social_cost(\n            start, goal, humans, static_obstacles, social_forces\n        )\n\n        return path\n\n    def calculate_social_forces(self, robot_pos, humans):\n        """Calculate social forces from humans on robot"""\n        forces = []\n\n        for human in humans:\n            if human[\'confidence\'] > 0.6:\n                human_pos = np.array(human[\'position_3d\'][:2])\n                robot_pos_2d = np.array([robot_pos.position.x, robot_pos.position.y])\n\n                # Calculate distance\n                distance = np.linalg.norm(human_pos - robot_pos_2d)\n\n                if distance < self.personal_space_radius:\n                    # Calculate repulsive force\n                    direction = robot_pos_2d - human_pos\n                    direction = direction / np.linalg.norm(direction)\n\n                    # Force magnitude decreases with distance\n                    force_magnitude = (self.personal_space_radius - distance) * 100\n                    force = direction * force_magnitude\n\n                    forces.append({\n                        \'position\': human_pos,\n                        \'force\': force,\n                        \'magnitude\': force_magnitude\n                    })\n\n        return forces\n\n    def plan_path_with_social_cost(self, start, goal, humans, static_obstacles, social_forces):\n        """Plan path considering both static and social costs"""\n        # Create enhanced costmap with social costs\n        enhanced_costmap = self.create_enhanced_costmap(\n            start, goal, humans, static_obstacles, social_forces\n        )\n\n        # Plan path using enhanced costmap\n        path = self.plan_path_on_costmap(start, goal, enhanced_costmap)\n\n        return path\n\n    def create_enhanced_costmap(self, start, goal, humans, static_obstacles, social_forces):\n        """Create costmap with both static and social costs"""\n        # Start with static costmap\n        base_costmap = self.create_static_costmap(start, goal, static_obstacles)\n\n        # Add social costs\n        for force_data in social_forces:\n            self.add_social_cost_to_costmap(\n                base_costmap,\n                force_data[\'position\'],\n                force_data[\'magnitude\']\n            )\n\n        return base_costmap\n\n    def add_social_cost_to_costmap(self, costmap, human_pos, force_magnitude):\n        """Add social cost around human position"""\n        # Calculate affected area\n        affected_radius = self.personal_space_radius / costmap.resolution\n\n        for dx in range(-int(affected_radius), int(affected_radius) + 1):\n            for dy in range(-int(affected_radius), int(affected_radius) + 1):\n                costmap_x = int(human_pos[0] / costmap.resolution) + dx\n                costmap_y = int(human_pos[1] / costmap.resolution) + dy\n\n                if (0 <= costmap_x < costmap.info.width and\n                    0 <= costmap_y < costmap.info.height):\n\n                    distance_to_human = np.sqrt(dx**2 + dy**2) * costmap.resolution\n                    if distance_to_human <= self.personal_space_radius:\n                        costmap_index = costmap_y * costmap.info.width + costmap_x\n                        cost_reduction = (1 - distance_to_human / self.personal_space_radius)\n                        additional_cost = force_magnitude * cost_reduction\n                        current_cost = costmap.data[costmap_index]\n                        new_cost = min(254, int(current_cost + additional_cost))\n                        costmap.data[costmap_index] = new_cost\n\nclass SocialForceModel:\n    def __init__(self):\n        self.pedestrian_repulsion_strength = 5.0\n        self.pedestrian_interaction_range = 2.0\n        self.wall_repulsion_strength = 10.0\n        self.wall_interaction_range = 1.0\n\n    def compute_social_force(self, agent_pos, agent_vel, other_agents, walls):\n        """Compute total social force on agent"""\n        total_force = np.zeros(2)\n\n        # Add self-propelling force toward goal\n        desired_velocity = self.compute_desired_velocity(agent_pos, agent_vel)\n        self_propelling_force = desired_velocity - agent_vel\n        total_force += self_propelling_force\n\n        # Add repulsive forces from other agents\n        for other_pos, other_vel in other_agents:\n            if np.linalg.norm(agent_pos - other_pos) < self.pedestrian_interaction_range:\n                repulsive_force = self.compute_agent_repulsion(\n                    agent_pos, other_pos, agent_vel, other_vel\n                )\n                total_force += repulsive_force\n\n        # Add repulsive forces from walls/obstacles\n        for wall in walls:\n            if self.distance_to_wall(agent_pos, wall) < self.wall_interaction_range:\n                wall_force = self.compute_wall_repulsion(agent_pos, wall)\n                total_force += wall_force\n\n        return total_force\n\n    def compute_agent_repulsion(self, pos1, pos2, vel1, vel2):\n        """Compute repulsive force between two agents"""\n        diff = pos1 - pos2\n        distance = np.linalg.norm(diff)\n\n        if distance < 0.1:  # Prevent division by zero\n            distance = 0.1\n\n        direction = diff / distance\n        relative_velocity = vel1 - vel2\n        interaction = np.dot(relative_velocity, direction)\n\n        # Social force formula\n        force_magnitude = self.pedestrian_repulsion_strength * np.exp(-distance) * interaction\n        repulsive_force = force_magnitude * direction\n\n        return repulsive_force\n'})}),"\n",(0,t.jsx)(e.h3,{id:"adaptive-navigation-for-dynamic-environments",children:"Adaptive Navigation for Dynamic Environments"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class AdaptiveNavigation:\n    def __init__(self):\n        self.environment_model = EnvironmentModel()\n        self.uncertainty_estimator = UncertaintyEstimator()\n        self.adaptation_controller = AdaptationController()\n\n    def adaptive_navigate(self, goal, sensor_data_stream):\n        """Navigate with adaptation to dynamic environments"""\n        initial_path = self.plan_initial_path(goal)\n\n        for sensor_data in sensor_data_stream:\n            # Update environment model\n            self.environment_model.update(sensor_data)\n\n            # Estimate uncertainty in current plan\n            uncertainty = self.uncertainty_estimator.estimate(\n                initial_path,\n                self.environment_model.get_dynamic_elements()\n            )\n\n            # Adapt navigation strategy based on uncertainty\n            adapted_path = self.adaptation_controller.adapt(\n                initial_path,\n                uncertainty,\n                self.environment_model.get_predictions()\n            )\n\n            # Execute adapted plan\n            success = self.execute_path(adapted_path)\n\n            if success:\n                return True\n\n        return False\n\nclass EnvironmentModel:\n    def __init__(self):\n        self.dynamic_objects = {}\n        self.static_map = None\n        self.flow_fields = {}\n\n    def update(self, sensor_data):\n        """Update environment model with new sensor data"""\n        # Update static map if available\n        if \'map\' in sensor_data:\n            self.static_map = sensor_data[\'map\']\n\n        # Update dynamic objects\n        if \'detections\' in sensor_data:\n            self.update_dynamic_objects(sensor_data[\'detections\'])\n\n        # Update flow fields for crowd simulation\n        if \'humans\' in sensor_data:\n            self.update_flow_fields(sensor_data[\'humans\'])\n\n    def update_dynamic_objects(self, detections):\n        """Update dynamic objects with new detections"""\n        for detection in detections:\n            obj_id = detection.get(\'id\', \'unknown\')\n\n            # Update or create object\n            if obj_id in self.dynamic_objects:\n                # Update existing object\n                self.dynamic_objects[obj_id].update(detection)\n            else:\n                # Create new object\n                self.dynamic_objects[obj_id] = DynamicObject(detection)\n\n    def predict_motion(self, time_horizon):\n        """Predict motion of dynamic objects"""\n        predictions = {}\n\n        for obj_id, obj in self.dynamic_objects.items():\n            predicted_path = obj.predict_motion(time_horizon)\n            predictions[obj_id] = predicted_path\n\n        return predictions\n\nclass DynamicObject:\n    def __init__(self, detection):\n        self.position = detection[\'position_3d\']\n        self.velocity = detection.get(\'velocity\', [0, 0, 0])\n        self.acceleration = detection.get(\'acceleration\', [0, 0, 0])\n        self.type = detection.get(\'class\', \'unknown\')\n        self.last_update = time.time()\n\n    def update(self, detection):\n        """Update object state with new detection"""\n        # Calculate new velocity from position change\n        new_position = detection[\'position_3d\']\n        time_diff = time.time() - self.last_update\n\n        if time_diff > 0:\n            new_velocity = [(new_pos - old_pos) / time_diff\n                           for new_pos, old_pos in zip(new_position, self.position)]\n\n            # Update acceleration\n            self.acceleration = [(new_vel - old_vel) / time_diff\n                               for new_vel, old_vel in zip(new_velocity, self.velocity)]\n\n            self.velocity = new_velocity\n\n        self.position = new_position\n        self.last_update = time.time()\n\n    def predict_motion(self, time_horizon, steps=10):\n        """Predict motion over time horizon"""\n        predictions = []\n        dt = time_horizon / steps\n\n        current_pos = self.position.copy()\n        current_vel = self.velocity.copy()\n\n        for _ in range(steps):\n            # Update position using kinematic equations\n            for i in range(3):  # x, y, z\n                current_pos[i] += current_vel[i] * dt + 0.5 * self.acceleration[i] * dt**2\n                current_vel[i] += self.acceleration[i] * dt\n\n            predictions.append(current_pos.copy())\n\n        return predictions\n\nclass UncertaintyEstimator:\n    def estimate(self, path, dynamic_elements):\n        """Estimate uncertainty in path given dynamic elements"""\n        uncertainty_map = np.zeros_like(path)\n\n        for i, waypoint in enumerate(path):\n            uncertainty = 0\n\n            # Calculate uncertainty from dynamic objects\n            for obj_id, obj in dynamic_elements.items():\n                distance = self.calculate_distance(waypoint, obj.position)\n                if distance < 5.0:  # Consider objects within 5m\n                    # Uncertainty increases with object velocity and proximity\n                    vel_magnitude = np.linalg.norm(obj.velocity)\n                    uncertainty += vel_magnitude / (distance + 0.1)\n\n            uncertainty_map[i] = uncertainty\n\n        return uncertainty_map\n\nclass AdaptationController:\n    def adapt(self, original_path, uncertainty, predictions):\n        """Adapt navigation plan based on uncertainty and predictions"""\n        if np.max(uncertainty) < 0.1:  # Low uncertainty\n            return original_path\n\n        # High uncertainty - replan with safety margins\n        safe_path = self.replan_with_safety(original_path, predictions)\n        return safe_path\n\n    def replan_with_safety(self, original_path, predictions):\n        """Replan considering predicted movements of dynamic objects"""\n        # This would implement a replanning algorithm that considers\n        # the predicted future positions of dynamic objects\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization-and-real-time-considerations",children:"Performance Optimization and Real-time Considerations"}),"\n",(0,t.jsx)(e.h3,{id:"real-time-navigation-optimization",children:"Real-time Navigation Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import threading\nimport queue\nimport time\n\nclass RealTimeNavigationOptimizer:\n    def __init__(self):\n        self.path_cache = {}\n        self.optimization_threads = []\n        self.scheduling_policy = \'earliest_deadline_first\'\n        self.max_navigation_frequency = 10.0  # Hz\n\n        # Initialize optimization components\n        self.path_smoother = PathSmoother()\n        self.collision_checker = CollisionChecker()\n        self.trajectory_optimizer = TrajectoryOptimizer()\n\n    def optimize_navigation_pipeline(self):\n        """Optimize navigation pipeline for real-time performance"""\n        # Use multi-threading for parallel processing\n        self.setup_parallel_processing()\n\n        # Implement priority-based scheduling\n        self.setup_priority_scheduling()\n\n        # Optimize memory usage\n        self.setup_memory_pooling()\n\n    def setup_parallel_processing(self):\n        """Setup parallel processing for navigation components"""\n        # Path planning thread\n        path_thread = threading.Thread(target=self.path_planning_worker)\n        path_thread.start()\n        self.optimization_threads.append(path_thread)\n\n        # Collision checking thread\n        collision_thread = threading.Thread(target=self.collision_checking_worker)\n        collision_thread.start()\n        self.optimization_threads.append(collision_thread)\n\n        # Trajectory optimization thread\n        traj_thread = threading.Thread(target=self.trajectory_optimization_worker)\n        traj_thread.start()\n        self.optimization_threads.append(traj_thread)\n\n    def path_planning_worker(self):\n        """Worker thread for path planning"""\n        path_request_queue = queue.Queue()\n\n        while True:\n            try:\n                request = path_request_queue.get(timeout=1.0)\n                path = self.compute_path_optimized(\n                    request[\'start\'],\n                    request[\'goal\'],\n                    request[\'costmap\']\n                )\n                request[\'result_queue\'].put(path)\n            except queue.Empty:\n                continue\n\n    def compute_path_optimized(self, start, goal, costmap):\n        """Optimized path computation with caching"""\n        # Create cache key\n        cache_key = self.create_path_cache_key(start, goal, costmap)\n\n        # Check cache first\n        if cache_key in self.path_cache:\n            return self.path_cache[cache_key]\n\n        # Compute path\n        path = self.a_star_planner.plan(start, goal, costmap)\n\n        # Cache result\n        self.path_cache[cache_key] = path\n\n        # Limit cache size\n        if len(self.path_cache) > 1000:\n            # Remove oldest entries\n            oldest_key = next(iter(self.path_cache))\n            del self.path_cache[oldest_key]\n\n        return path\n\n    def setup_priority_scheduling(self):\n        """Setup priority-based task scheduling"""\n        self.task_scheduler = TaskScheduler(policy=self.scheduling_policy)\n\n    def setup_memory_pooling(self):\n        """Setup memory pooling to reduce allocation overhead"""\n        self.memory_pool = MemoryPool()\n\nclass TaskScheduler:\n    def __init__(self, policy=\'earliest_deadline_first\'):\n        self.policy = policy\n        self.tasks = []\n        self.lock = threading.Lock()\n\n    def add_task(self, task, priority=0, deadline=None):\n        """Add task to scheduler"""\n        with self.lock:\n            self.tasks.append({\n                \'task\': task,\n                \'priority\': priority,\n                \'deadline\': deadline,\n                \'arrival_time\': time.time()\n            })\n\n    def schedule_next(self):\n        """Get next task based on scheduling policy"""\n        if not self.tasks:\n            return None\n\n        with self.lock:\n            if self.policy == \'earliest_deadline_first\':\n                # Sort by deadline\n                self.tasks.sort(key=lambda x: x[\'deadline\'] or float(\'inf\'))\n            elif self.policy == \'priority\':\n                # Sort by priority (higher first)\n                self.tasks.sort(key=lambda x: x[\'priority\'], reverse=True)\n\n            return self.tasks.pop(0) if self.tasks else None\n\nclass MemoryPool:\n    def __init__(self, initial_size=100):\n        self.pool = queue.Queue()\n        self.lock = threading.Lock()\n\n        # Pre-allocate memory blocks\n        for _ in range(initial_size):\n            self.pool.put(self.create_memory_block())\n\n    def get_block(self):\n        """Get memory block from pool"""\n        try:\n            return self.pool.get_nowait()\n        except queue.Empty:\n            # Create new block if pool is empty\n            return self.create_memory_block()\n\n    def return_block(self, block):\n        """Return memory block to pool"""\n        self.pool.put(block)\n\n    def create_memory_block(self):\n        """Create a new memory block"""\n        # This would create a reusable data structure\n        return {\'data\': None, \'size\': 0}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"practical-applications-in-humanoid-robotics",children:"Practical Applications in Humanoid Robotics"}),"\n",(0,t.jsx)(e.h3,{id:"humanoid-specific-navigation-challenges",children:"Humanoid-Specific Navigation Challenges"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class HumanoidNavigationChallenges:\n    def __init__(self):\n        self.balance_manager = BalanceManager()\n        self.step_planner = StepPlanner()\n        self.gait_adaptor = GaitAdaptor()\n\n    def handle_narrow_passages(self, path, costmap):\n        """Handle navigation through narrow passages"""\n        # Check if humanoid can fit through passages\n        feasible_path = self.adapt_path_for_humanoid_width(path, costmap)\n\n        if not feasible_path:\n            # Find alternative route\n            alternative_path = self.find_wider_route(path, costmap)\n            return alternative_path\n\n        return feasible_path\n\n    def adapt_path_for_humanoid_width(self, path, costmap):\n        """Adapt path considering humanoid width"""\n        humanoid_width = 0.6  # meters (shoulder width)\n        safety_margin = 0.2   # additional safety\n\n        adapted_path = []\n        for pose in path.poses:\n            # Check if there\'s enough space on both sides\n            if self.has_sufficient_width(pose, costmap, humanoid_width + safety_margin):\n                adapted_path.append(pose)\n            else:\n                # Find alternative waypoint\n                alternative = self.find_alternative_waypoint(pose, costmap)\n                if alternative:\n                    adapted_path.append(alternative)\n\n        return adapted_path\n\n    def has_sufficient_width(self, pose, costmap, required_width):\n        """Check if there\'s sufficient width at pose location"""\n        # Check perpendicular directions to the path\n        pose_angle = self.extract_yaw_from_pose(pose)\n        perpendicular_angle1 = pose_angle + np.pi/2\n        perpendicular_angle2 = pose_angle - np.pi/2\n\n        # Check both perpendicular directions\n        for angle in [perpendicular_angle1, perpendicular_angle2]:\n            # Sample points at required_width/2 distance\n            sample_point = self.move_in_direction(\n                pose.position.x, pose.position.y,\n                angle, required_width/2\n            )\n\n            if not self.is_point_traversable(sample_point, costmap):\n                return False\n\n        return True\n\n    def handle_rough_terrain(self, path, terrain_info):\n        """Handle navigation on rough terrain"""\n        adapted_path = []\n\n        for i, pose in enumerate(path.poses):\n            # Check terrain characteristics at this point\n            terrain_type = self.classify_terrain(pose, terrain_info)\n\n            if terrain_type in [\'rough\', \'uneven\', \'sloped\']:\n                # Adapt path for terrain\n                adapted_pose = self.adapt_pose_for_terrain(pose, terrain_type)\n                adapted_path.append(adapted_pose)\n            else:\n                adapted_path.append(pose)\n\n        return adapted_path\n\n    def adapt_pose_for_terrain(self, pose, terrain_type):\n        """Adapt pose based on terrain type"""\n        adapted_pose = PoseStamped()\n        adapted_pose.header = pose.header\n        adapted_pose.pose = pose.pose\n\n        if terrain_type == \'sloped\':\n            # Adjust for slope by modifying step characteristics\n            self.adjust_for_slope(adapted_pose)\n        elif terrain_type == \'rough\':\n            # Use more conservative step parameters\n            self.use_conservative_steps(adapted_pose)\n        elif terrain_type == \'uneven\':\n            # Plan steps more carefully\n            self.plan_careful_steps(adapted_pose)\n\n        return adapted_pose\n\n    def adjust_for_slope(self, pose):\n        """Adjust navigation for sloped terrain"""\n        # Modify step length and height based on slope\n        slope_angle = self.calculate_slope_angle(pose)\n\n        # Reduce step length on steep slopes\n        if abs(slope_angle) > 15:  # 15 degrees\n            # This would modify the step planning parameters\n            pass\n\n    def handle_door_navigation(self, door_pose, approach_angle=0):\n        """Handle navigation through doors"""\n        # Plan approach to door\n        approach_path = self.plan_door_approach(door_pose, approach_angle)\n\n        # Execute door passage maneuver\n        passage_success = self.execute_door_passage(door_pose)\n\n        if passage_success:\n            # Continue with navigation\n            continue_path = self.plan_post_door_path(door_pose)\n            return approach_path + continue_path\n\n        return approach_path\n\n    def plan_door_approach(self, door_pose, approach_angle):\n        """Plan approach to door with proper orientation"""\n        approach_poses = []\n\n        # Calculate approach points\n        for distance in [2.0, 1.0, 0.5]:  # meters from door\n            approach_x = door_pose.position.x - distance * np.cos(approach_angle)\n            approach_y = door_pose.position.y - distance * np.sin(approach_angle)\n\n            approach_pose = PoseStamped()\n            approach_pose.pose.position.x = approach_x\n            approach_pose.pose.position.y = approach_y\n            approach_pose.pose.orientation = self.create_orientation(approach_angle)\n\n            approach_poses.append(approach_pose)\n\n        return approach_poses\n\nclass BalanceManager:\n    def __init__(self):\n        self.zmp_controller = ZMPController()\n        self.com_controller = COMController()\n        self.ankle_strategies = AnkleStrategies()\n\n    def maintain_balance_during_navigation(self, robot_state, control_command):\n        """Maintain balance during navigation"""\n        # Calculate desired ZMP based on motion\n        desired_zmp = self.zmp_controller.calculate_desired_zmp(\n            control_command, robot_state\n        )\n\n        # Calculate CoM trajectory for balance\n        com_trajectory = self.com_controller.calculate_balance_trajectory(\n            desired_zmp, robot_state\n        )\n\n        # Generate balance control commands\n        balance_commands = self.ankle_strategies.generate_balance_commands(\n            com_trajectory, robot_state\n        )\n\n        return balance_commands\n\nclass StepPlanner:\n    def __init__(self):\n        self.step_height = 0.1\n        self.step_length = 0.3\n        self.step_duration = 1.0\n        self.foot_placement_optimizer = FootPlacementOptimizer()\n\n    def plan_step_sequence(self, path, robot_state):\n        """Plan sequence of steps to follow path"""\n        step_sequence = []\n\n        for i in range(len(path.poses) - 1):\n            start_pose = path.poses[i]\n            end_pose = path.poses[i + 1]\n\n            # Plan steps between poses\n            steps = self.plan_steps_between_poses(start_pose, end_pose)\n            step_sequence.extend(steps)\n\n        return step_sequence\n\n    def plan_steps_between_poses(self, start_pose, end_pose):\n        """Plan individual steps between two poses"""\n        # Calculate distance and direction\n        dx = end_pose.position.x - start_pose.position.x\n        dy = end_pose.position.y - start_pose.position.y\n        distance = np.sqrt(dx**2 + dy**2)\n        direction = np.arctan2(dy, dx)\n\n        # Calculate number of steps needed\n        num_steps = int(distance / self.step_length) + 1\n\n        steps = []\n        for i in range(num_steps):\n            step_fraction = (i + 1) / num_steps\n            step_x = start_pose.position.x + step_fraction * dx\n            step_y = start_pose.position.y + step_fraction * dy\n\n            step_pose = Pose()\n            step_pose.position.x = step_x\n            step_pose.position.y = step_y\n            step_pose.position.z = 0  # Ground level\n            step_pose.orientation = self.calculate_step_orientation(\n                direction, step_fraction\n            )\n\n            steps.append(step_pose)\n\n        return steps\n'})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices-for-nav2-configuration",children:"Best Practices for Nav2 Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"configuration-optimization",children:"Configuration Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class Nav2ConfigurationOptimizer:\n    def __init__(self):\n        self.param_grids = {\n            'dwb': {\n                'max_vel_x': [0.1, 0.2, 0.3, 0.4, 0.5],\n                'min_vel_x': [0.05, 0.1, 0.15],\n                'max_vel_theta': [0.5, 1.0, 1.5, 2.0],\n                'min_vel_theta': [0.1, 0.2, 0.3],\n                'acc_lim_x': [1.0, 2.0, 3.0],\n                'acc_lim_theta': [1.0, 2.0, 3.0]\n            },\n            'global_planner': {\n                'planner_frequency': [0.5, 1.0, 2.0],\n                'max_planning_attempts': [5, 10, 15]\n            },\n            'costmap': {\n                'inflation_radius': [0.3, 0.5, 0.7, 1.0],\n                'cost_scaling_factor': [1.0, 2.0, 3.0, 5.0, 10.0]\n            }\n        }\n\n    def optimize_parameters(self, environment_type='indoor'):\n        \"\"\"Optimize Nav2 parameters for specific environment\"\"\"\n        if environment_type == 'indoor':\n            return self.optimize_indoor_parameters()\n        elif environment_type == 'outdoor':\n            return self.optimize_outdoor_parameters()\n        elif environment_type == 'crowded':\n            return self.optimize_crowded_parameters()\n        else:\n            return self.get_default_parameters()\n\n    def optimize_indoor_parameters(self):\n        \"\"\"Optimize for indoor environments\"\"\"\n        params = {\n            # Local planner parameters\n            'dwb_local_planner': {\n                'max_vel_x': 0.3,\n                'min_vel_x': 0.05,\n                'max_vel_theta': 1.0,\n                'min_vel_theta': 0.1,\n                'acc_lim_x': 1.0,\n                'acc_lim_theta': 2.0,\n                'xy_goal_tolerance': 0.2,\n                'yaw_goal_tolerance': 0.1\n            },\n            # Costmap parameters\n            'local_costmap': {\n                'inflation_radius': 0.5,\n                'cost_scaling_factor': 5.0\n            },\n            'global_costmap': {\n                'inflation_radius': 0.7,\n                'cost_scaling_factor': 3.0\n            }\n        }\n        return params\n\n    def optimize_crowded_parameters(self):\n        \"\"\"Optimize for crowded environments\"\"\"\n        params = {\n            # More conservative velocities for safety\n            'dwb_local_planner': {\n                'max_vel_x': 0.2,  # Slower in crowds\n                'min_vel_x': 0.05,\n                'max_vel_theta': 0.8,  # More careful turning\n                'min_vel_theta': 0.1,\n                'acc_lim_x': 0.8,    # Smoother acceleration\n                'acc_lim_theta': 1.5,\n                'xy_goal_tolerance': 0.3,  # More tolerant for dynamic environments\n                'yaw_goal_tolerance': 0.2\n            },\n            # Larger safety margins\n            'local_costmap': {\n                'inflation_radius': 0.8,  # Larger safety bubble\n                'cost_scaling_factor': 8.0\n            },\n            'global_costmap': {\n                'inflation_radius': 1.0,\n                'cost_scaling_factor': 5.0\n            }\n        }\n        return params\n\n    def validate_configuration(self, config):\n        \"\"\"Validate Nav2 configuration\"\"\"\n        issues = []\n\n        # Check for common configuration issues\n        if config['dwb_local_planner']['max_vel_x'] < config['dwb_local_planner']['min_vel_x']:\n            issues.append(\"max_vel_x should be greater than min_vel_x\")\n\n        if config['dwb_local_planner']['acc_lim_x'] < 0.1:\n            issues.append(\"acc_lim_x too low, may cause poor performance\")\n\n        if config['local_costmap']['inflation_radius'] < 0.1:\n            issues.append(\"inflation_radius too small, may cause collisions\")\n\n        return issues\n"})}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Navigation and path planning with Nav2 provides sophisticated capabilities for humanoid robots, addressing the unique challenges of bipedal locomotion, balance maintenance, and human-scale environment interaction. The integration of perception data from Isaac ROS components enables advanced navigation strategies that consider both static and dynamic environmental elements."}),"\n",(0,t.jsx)(e.p,{children:"The component-based architecture of Nav2 allows for customization of navigation behaviors to suit humanoid-specific requirements, including specialized planners for step-constrained locomotion, social navigation capabilities, and adaptive strategies for dynamic environments. Proper configuration and optimization of Nav2 parameters ensure that humanoid robots can navigate complex environments safely and efficiently while maintaining balance and avoiding obstacles."}),"\n",(0,t.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Nav2 Documentation: ",(0,t.jsx)(e.a,{href:"https://navigation.ros.org/",children:"https://navigation.ros.org/"})]}),"\n",(0,t.jsx)(e.li,{children:'"Principles of Robot Motion" by Howie Choset et al.'}),"\n",(0,t.jsx)(e.li,{children:'"Robotics, Vision and Control" by Peter Corke'}),"\n",(0,t.jsx)(e.li,{children:'"Probabilistic Robotics" by Sebastian Thrun, Wolfram Burgard, and Dieter Fox'}),"\n",(0,t.jsx)(e.li,{children:'"Springer Handbook of Robotics" by Siciliano and Khatib'}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(_,{...n})}):_(n)}},8453(n,e,a){a.d(e,{R:()=>s,x:()=>r});var t=a(6540);const o={},i=t.createContext(o);function s(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);