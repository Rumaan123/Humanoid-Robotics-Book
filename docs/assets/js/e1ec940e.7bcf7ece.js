"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[447],{8038(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var o=t(4848),i=t(8453);const r={sidebar_position:7},s="Architectural View of Robot Control Pipelines: From Perception to Action",a={id:"module-1/control-pipelines",title:"Architectural View of Robot Control Pipelines: From Perception to Action",description:"Overview",source:"@site/docs/module-1/control-pipelines.md",sourceDirName:"module-1",slug:"/module-1/control-pipelines",permalink:"/Humanoid-Robotics-Book/docs/module-1/control-pipelines",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Humanoid Robot Modeling with URDF: Unified Robot Description Format",permalink:"/Humanoid-Robotics-Book/docs/module-1/urdf-modeling"},next:{title:"Module 2: The Digital Twin (Gazebo & Unity)",permalink:"/Humanoid-Robotics-Book/docs/module-2/"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Robot Control Pipelines",id:"introduction-to-robot-control-pipelines",level:2},{value:"What is a Control Pipeline?",id:"what-is-a-control-pipeline",level:3},{value:"Key Characteristics of Control Pipelines",id:"key-characteristics-of-control-pipelines",level:3},{value:"Control Pipeline in Physical AI Context",id:"control-pipeline-in-physical-ai-context",level:3},{value:"Hierarchical Control Architecture",id:"hierarchical-control-architecture",level:2},{value:"The Three-Tier Control Architecture",id:"the-three-tier-control-architecture",level:3},{value:"Low-Level Control Layer",id:"low-level-control-layer",level:3},{value:"Mid-Level Control Layer",id:"mid-level-control-layer",level:3},{value:"High-Level Control Layer",id:"high-level-control-layer",level:3},{value:"Control Pipeline Patterns",id:"control-pipeline-patterns",level:2},{value:"Feedback Control Loop Pattern",id:"feedback-control-loop-pattern",level:3},{value:"State Machine Pattern",id:"state-machine-pattern",level:3},{value:"Component-Based Architecture",id:"component-based-architecture",level:3},{value:"Safety and Fault Tolerance",id:"safety-and-fault-tolerance",level:2},{value:"Safety Architecture",id:"safety-architecture",level:3},{value:"Fault Detection and Recovery",id:"fault-detection-and-recovery",level:3},{value:"Real-time Performance Considerations",id:"real-time-performance-considerations",level:2},{value:"Timing Analysis",id:"timing-analysis",level:3},{value:"Priority-Based Scheduling",id:"priority-based-scheduling",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"ROS 2 Control Architecture",id:"ros-2-control-architecture",level:3},{value:"Practical Applications in Humanoid Robotics",id:"practical-applications-in-humanoid-robotics",level:2},{value:"Walking Control Pipeline",id:"walking-control-pipeline",level:3},{value:"Manipulation Control Pipeline",id:"manipulation-control-pipeline",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Pipeline Parallelization",id:"pipeline-parallelization",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"architectural-view-of-robot-control-pipelines-from-perception-to-action",children:"Architectural View of Robot Control Pipelines: From Perception to Action"}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"Robot control pipelines represent the systematic flow of information and commands from sensor perception through decision-making to actuator execution in humanoid robotic systems. In Physical AI applications, these pipelines form the critical infrastructure that enables robots to perceive their environment, reason about their state and goals, and execute appropriate physical actions. Understanding the architectural patterns of robot control pipelines is essential for developing robust, efficient, and safe humanoid robots that can operate in complex, dynamic environments."}),"\n",(0,o.jsx)(n.p,{children:"The architectural view encompasses multiple levels of control, from low-level motor control to high-level cognitive planning, each with distinct timing requirements, computational needs, and safety considerations. This hierarchical structure enables the coordination of diverse subsystems while maintaining the real-time performance necessary for stable robot operation."}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this section, you should be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Understand the hierarchical structure of robot control pipelines and their timing requirements"}),"\n",(0,o.jsx)(n.li,{children:"Design multi-layered control architectures for humanoid robots with appropriate feedback loops"}),"\n",(0,o.jsx)(n.li,{children:"Integrate perception, planning, and control components into cohesive pipeline architectures"}),"\n",(0,o.jsx)(n.li,{children:"Implement safety mechanisms and fault tolerance within control pipeline architectures"}),"\n",(0,o.jsx)(n.li,{children:"Analyze and optimize control pipeline performance for real-time humanoid robot operation"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"introduction-to-robot-control-pipelines",children:"Introduction to Robot Control Pipelines"}),"\n",(0,o.jsx)(n.h3,{id:"what-is-a-control-pipeline",children:"What is a Control Pipeline?"}),"\n",(0,o.jsxs)(n.p,{children:["A ",(0,o.jsx)(n.strong,{children:"robot control pipeline"})," is an architectural pattern that organizes the flow of information and control commands through multiple processing layers, each operating at different temporal and spatial scales. The pipeline typically flows from sensor inputs at the bottom to actuator commands at the top, with intermediate layers for state estimation, planning, and coordination."]}),"\n",(0,o.jsx)(n.h3,{id:"key-characteristics-of-control-pipelines",children:"Key Characteristics of Control Pipelines"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Hierarchical Structure"}),": Multiple layers of control with different update rates and responsibilities"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Real-time Requirements"}),": Strict timing constraints for stable robot operation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Feedback Integration"}),": Continuous monitoring and adjustment based on sensor data"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Safety Criticality"}),": Multiple layers of safety checks and emergency procedures"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Distributed Processing"}),": Components may run on different hardware platforms"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"control-pipeline-in-physical-ai-context",children:"Control Pipeline in Physical AI Context"}),"\n",(0,o.jsx)(n.p,{children:"In Physical AI systems, control pipelines bridge the gap between digital intelligence and physical action, requiring careful consideration of:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Latency"}),": Time delays between perception and action"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Accuracy"}),": Precision of state estimation and control commands"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robustness"}),": Ability to handle sensor noise and environmental disturbances"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Adaptability"}),": Capacity to adjust to changing conditions and goals"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"hierarchical-control-architecture",children:"Hierarchical Control Architecture"}),"\n",(0,o.jsx)(n.h3,{id:"the-three-tier-control-architecture",children:"The Three-Tier Control Architecture"}),"\n",(0,o.jsx)(n.p,{children:"Robot control systems typically follow a three-tier architecture:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Low-Level Control (1-10 kHz)"}),": Direct motor control and hardware interfaces"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Mid-Level Control (10-100 Hz)"}),": Trajectory following and motion control"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"High-Level Control (1-10 Hz)"}),": Planning, decision making, and task execution"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"low-level-control-layer",children:"Low-Level Control Layer"}),"\n",(0,o.jsx)(n.p,{children:"The low-level control layer handles direct hardware interfaces and motor control:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom std_msgs.msg import Float64MultiArray\nimport numpy as np\n\nclass LowLevelController(Node):\n    def __init__(self):\n        super().__init__(\'low_level_controller\')\n\n        # Publishers for motor commands\n        self.joint_cmd_pub = self.create_publisher(\n            Float64MultiArray,\n            \'/hardware_interface/joint_commands\',\n            10\n        )\n\n        # Subscribers for sensor feedback\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        # High-frequency control loop (1kHz)\n        self.control_timer = self.create_timer(0.001, self.low_level_control)\n\n        self.current_positions = {}\n        self.current_velocities = {}\n        self.current_efforts = {}\n        self.desired_positions = {}\n        self.desired_velocities = {}\n\n    def joint_state_callback(self, msg):\n        """Update current joint states from hardware feedback"""\n        for i, name in enumerate(msg.name):\n            if i < len(msg.position):\n                self.current_positions[name] = msg.position[i]\n            if i < len(msg.velocity):\n                self.current_velocities[name] = msg.velocity[i]\n            if i < len(msg.effort):\n                self.current_efforts[name] = msg.effort[i]\n\n    def low_level_control(self):\n        """High-frequency control loop for motor commands"""\n        # Calculate control commands using PID or other control algorithms\n        commands = Float64MultiArray()\n\n        for joint_name in self.desired_positions.keys():\n            # Simple PD controller example\n            current_pos = self.current_positions.get(joint_name, 0.0)\n            current_vel = self.current_velocities.get(joint_name, 0.0)\n            desired_pos = self.desired_positions.get(joint_name, 0.0)\n            desired_vel = self.desired_velocities.get(joint_name, 0.0)\n\n            # Calculate position and velocity errors\n            pos_error = desired_pos - current_pos\n            vel_error = desired_vel - current_vel\n\n            # PD control law\n            kp = 100.0  # Position gain\n            kd = 10.0   # Velocity gain\n            control_effort = kp * pos_error + kd * vel_error\n\n            commands.data.append(control_effort)\n\n        self.joint_cmd_pub.publish(commands)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"mid-level-control-layer",children:"Mid-Level Control Layer"}),"\n",(0,o.jsx)(n.p,{children:"The mid-level control layer handles trajectory following and motion control:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nfrom sensor_msgs.msg import JointState\nfrom builtin_interfaces.msg import Duration\nimport numpy as np\nfrom scipy.interpolate import interp1d\n\nclass MidLevelController(Node):\n    def __init__(self):\n        super().__init__(\'mid_level_controller\')\n\n        # Trajectory subscribers and publishers\n        self.trajectory_sub = self.create_subscription(\n            JointTrajectory,\n            \'/joint_trajectory_controller/joint_trajectory\',\n            self.trajectory_callback,\n            10\n        )\n\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        # Publisher for low-level commands\n        self.low_level_cmd_pub = self.create_publisher(\n            Float64MultiArray,\n            \'/low_level_commands\',\n            10\n        )\n\n        # Control loop (100Hz)\n        self.control_timer = self.create_timer(0.01, self.mid_level_control)\n\n        self.active_trajectory = None\n        self.trajectory_start_time = None\n        self.current_trajectory_index = 0\n        self.current_positions = {}\n        self.current_velocities = {}\n\n    def trajectory_callback(self, msg):\n        """Receive and process joint trajectory commands"""\n        self.active_trajectory = msg\n        self.trajectory_start_time = self.get_clock().now()\n        self.current_trajectory_index = 0\n\n    def joint_state_callback(self, msg):\n        """Update current joint states"""\n        for i, name in enumerate(msg.name):\n            if i < len(msg.position):\n                self.current_positions[name] = msg.position[i]\n            if i < len(msg.velocity):\n                self.current_velocities[name] = msg.velocity[i]\n\n    def mid_level_control(self):\n        """Execute trajectory following control"""\n        if self.active_trajectory is None:\n            return\n\n        # Calculate current time relative to trajectory start\n        current_time = (self.get_clock().now() - self.trajectory_start_time).nanoseconds * 1e-9\n\n        # Get desired positions and velocities from trajectory\n        desired_positions = {}\n        desired_velocities = {}\n\n        # Interpolate trajectory points based on current time\n        for i, point in enumerate(self.active_trajectory.points):\n            point_time = point.time_from_start.sec + point.time_from_start.nanosec * 1e-9\n\n            if i == 0:\n                # First point\n                for j, joint_name in enumerate(self.active_trajectory.joint_names):\n                    desired_positions[joint_name] = point.positions[j]\n                    if point.velocities:\n                        desired_velocities[joint_name] = point.velocities[j]\n            elif point_time >= current_time:\n                # Interpolate between previous and current point\n                prev_point = self.active_trajectory.points[i-1]\n                prev_time = prev_point.time_from_start.sec + prev_point.time_from_start.nanosec * 1e-9\n\n                if point_time > prev_time:\n                    alpha = (current_time - prev_time) / (point_time - prev_time)\n                    for j, joint_name in enumerate(self.active_trajectory.joint_names):\n                        prev_pos = prev_point.positions[j]\n                        curr_pos = point.positions[j]\n                        desired_positions[joint_name] = prev_pos + alpha * (curr_pos - prev_pos)\n\n                        if point.velocities and prev_point.velocities:\n                            prev_vel = prev_point.velocities[j]\n                            curr_vel = point.velocities[j]\n                            desired_velocities[joint_name] = prev_vel + alpha * (curr_vel - prev_vel)\n                break\n\n        # Publish to low-level controller\n        commands = Float64MultiArray()\n        commands.data = list(desired_positions.values())\n\n        self.low_level_cmd_pub.publish(commands)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"high-level-control-layer",children:"High-Level Control Layer"}),"\n",(0,o.jsx)(n.p,{children:"The high-level control layer handles planning, decision making, and task execution:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import PoseStamped\nfrom moveit_msgs.msg import MoveItErrorCodes\nfrom moveit_msgs.srv import GetPositionIK, GetPositionFK\nimport numpy as np\n\nclass HighLevelController(Node):\n    def __init__(self):\n        super().__init__(\'high_level_controller\')\n\n        # Publishers for high-level commands\n        self.task_pub = self.create_publisher(String, \'/task_commands\', 10)\n\n        # Service clients for planning\n        self.ik_client = self.create_client(\n            GetPositionIK,\n            \'/compute_ik\'\n        )\n        self.fk_client = self.create_client(\n            GetPositionFK,\n            \'/compute_fk\'\n        )\n\n        # Task execution timer (1Hz)\n        self.task_timer = self.create_timer(1.0, self.high_level_planning)\n\n        self.current_task = None\n        self.task_queue = []\n        self.robot_state = None\n\n    def high_level_planning(self):\n        """High-level planning and task execution"""\n        if not self.task_queue and self.current_task is None:\n            # Generate new tasks based on goals or environment\n            self.generate_tasks()\n\n        if self.task_queue and self.current_task is None:\n            # Start next task\n            self.current_task = self.task_queue.pop(0)\n            self.execute_task(self.current_task)\n\n    def generate_tasks(self):\n        """Generate tasks based on current state and goals"""\n        # Example: Generate walking tasks based on navigation goals\n        # This would integrate with perception and planning systems\n        pass\n\n    def execute_task(self, task):\n        """Execute a high-level task"""\n        # Break down task into mid-level trajectory commands\n        # This might involve path planning, inverse kinematics, etc.\n        pass\n'})}),"\n",(0,o.jsx)(n.h2,{id:"control-pipeline-patterns",children:"Control Pipeline Patterns"}),"\n",(0,o.jsx)(n.h3,{id:"feedback-control-loop-pattern",children:"Feedback Control Loop Pattern"}),"\n",(0,o.jsx)(n.p,{children:"The fundamental pattern in robot control is the feedback control loop:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class FeedbackController:\n    def __init__(self, dt=0.01):\n        self.dt = dt\n        self.integral_error = 0.0\n        self.previous_error = 0.0\n\n    def update(self, setpoint, measurement):\n        """Standard PID feedback control"""\n        error = setpoint - measurement\n\n        # Proportional term\n        p_term = error\n\n        # Integral term\n        self.integral_error += error * self.dt\n\n        # Derivative term\n        derivative_error = (error - self.previous_error) / self.dt\n        self.previous_error = error\n\n        # PID output\n        output = (1.0 * p_term +  # kp\n                 0.1 * self.integral_error +  # ki\n                 0.05 * derivative_error)  # kd\n\n        return output\n'})}),"\n",(0,o.jsx)(n.h3,{id:"state-machine-pattern",children:"State Machine Pattern"}),"\n",(0,o.jsx)(n.p,{children:"State machines are commonly used for task-level control:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from enum import Enum\n\nclass RobotState(Enum):\n    IDLE = 1\n    WALKING = 2\n    STANDING = 3\n    FALLING = 4\n    RECOVERING = 5\n\nclass StateMachineController:\n    def __init__(self):\n        self.current_state = RobotState.IDLE\n        self.state_start_time = 0.0\n\n    def update(self, sensor_data, time):\n        """State transition logic"""\n        new_state = self.current_state\n\n        # State transition logic\n        if self.current_state == RobotState.IDLE:\n            if self.should_start_walking(sensor_data):\n                new_state = RobotState.WALKING\n        elif self.current_state == RobotState.WALKING:\n            if self.should_stop_walking(sensor_data):\n                new_state = RobotState.STANDING\n            elif self.is_falling(sensor_data):\n                new_state = RobotState.FALLING\n        elif self.current_state == RobotState.FALLING:\n            if self.should_recover(sensor_data):\n                new_state = RobotState.RECOVERING\n        elif self.current_state == RobotState.RECOVERING:\n            if self.is_stable(sensor_data):\n                new_state = RobotState.STANDING\n\n        if new_state != self.current_state:\n            self.exit_state(self.current_state)\n            self.current_state = new_state\n            self.state_start_time = time\n            self.enter_state(self.current_state)\n\n        # Execute state-specific control\n        return self.execute_state(sensor_data)\n\n    def enter_state(self, state):\n        """Actions to take when entering a state"""\n        pass\n\n    def exit_state(self, state):\n        """Actions to take when exiting a state"""\n        pass\n\n    def execute_state(self, sensor_data):\n        """Execute control logic for current state"""\n        pass\n'})}),"\n",(0,o.jsx)(n.h3,{id:"component-based-architecture",children:"Component-Based Architecture"}),"\n",(0,o.jsx)(n.p,{children:"Modular components enable flexible pipeline composition:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class ControlComponent:\n    \"\"\"Base class for control pipeline components\"\"\"\n    def __init__(self, name):\n        self.name = name\n        self.inputs = {}\n        self.outputs = {}\n        self.parameters = {}\n\n    def update(self, inputs):\n        \"\"\"Process inputs and generate outputs\"\"\"\n        self.inputs = inputs\n        self.outputs = self.process(inputs)\n        return self.outputs\n\n    def process(self, inputs):\n        \"\"\"Implement specific processing logic\"\"\"\n        raise NotImplementedError\n\nclass PerceptionComponent(ControlComponent):\n    \"\"\"Component for processing sensor data\"\"\"\n    def process(self, inputs):\n        # Process raw sensor data into meaningful information\n        processed_data = {}\n\n        if 'raw_sensors' in inputs:\n            # Example: process IMU data for orientation\n            imu_data = inputs['raw_sensors'].get('imu', {})\n            processed_data['orientation'] = self.process_orientation(imu_data)\n\n        if 'camera' in inputs:\n            # Example: process camera data for obstacle detection\n            processed_data['obstacles'] = self.detect_obstacles(inputs['camera'])\n\n        return processed_data\n\nclass PlanningComponent(ControlComponent):\n    \"\"\"Component for path planning and trajectory generation\"\"\"\n    def process(self, inputs):\n        # Generate trajectories based on goals and current state\n        trajectory = {}\n\n        if 'goal' in inputs and 'current_state' in inputs:\n            trajectory = self.plan_trajectory(\n                inputs['goal'],\n                inputs['current_state'],\n                inputs.get('obstacles', [])\n            )\n\n        return {'trajectory': trajectory}\n\nclass ControlComponent(ControlComponent):\n    \"\"\"Component for low-level control\"\"\"\n    def process(self, inputs):\n        # Generate motor commands from trajectories\n        commands = {}\n\n        if 'trajectory' in inputs and 'current_state' in inputs:\n            commands = self.generate_commands(\n                inputs['trajectory'],\n                inputs['current_state']\n            )\n\n        return {'motor_commands': commands}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"safety-and-fault-tolerance",children:"Safety and Fault Tolerance"}),"\n",(0,o.jsx)(n.h3,{id:"safety-architecture",children:"Safety Architecture"}),"\n",(0,o.jsx)(n.p,{children:"Safety is paramount in humanoid robot control pipelines:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class SafetyMonitor:\n    def __init__(self):\n        self.emergency_stop = False\n        self.safety_limits = {\n            'joint_position': {'min': -3.14, 'max': 3.14},\n            'joint_velocity': {'max': 5.0},\n            'torque': {'max': 100.0},\n            'imu_angle': {'max': 0.5}  # 30 degrees\n        }\n\n    def check_safety(self, robot_state):\n        \"\"\"Check if robot state is within safe limits\"\"\"\n        violations = []\n\n        # Check joint positions\n        for joint_name, position in robot_state.get('joint_positions', {}).items():\n            if (position < self.safety_limits['joint_position']['min'] or\n                position > self.safety_limits['joint_position']['max']):\n                violations.append(f'Joint {joint_name} position limit violation')\n\n        # Check joint velocities\n        for joint_name, velocity in robot_state.get('joint_velocities', {}).items():\n            if abs(velocity) > self.safety_limits['joint_velocity']['max']:\n                violations.append(f'Joint {joint_name} velocity limit violation')\n\n        # Check IMU for dangerous angles\n        imu_orientation = robot_state.get('imu_orientation', {})\n        if 'roll' in imu_orientation and abs(imu_orientation['roll']) > self.safety_limits['imu_angle']['max']:\n            violations.append('Dangerous roll angle detected')\n\n        if violations:\n            self.emergency_stop = True\n            return False, violations\n\n        return True, []\n\n    def reset_safety(self):\n        \"\"\"Reset emergency stop state\"\"\"\n        self.emergency_stop = False\n"})}),"\n",(0,o.jsx)(n.h3,{id:"fault-detection-and-recovery",children:"Fault Detection and Recovery"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class FaultDetector:\n    def __init__(self):\n        self.fault_history = {}\n        self.recovery_strategies = {}\n\n    def detect_faults(self, sensor_data, control_outputs):\n        """Detect potential faults in the system"""\n        faults = []\n\n        # Check for sensor failures\n        if self.is_sensor_faulty(sensor_data):\n            faults.append(\'Sensor fault detected\')\n\n        # Check for actuator failures\n        if self.is_actuator_faulty(control_outputs):\n            faults.append(\'Actuator fault detected\')\n\n        # Check for unexpected behavior\n        if self.is_behavior_unexpected(sensor_data):\n            faults.append(\'Unexpected behavior detected\')\n\n        return faults\n\n    def is_sensor_faulty(self, sensor_data):\n        """Check for sensor anomalies"""\n        # Example: Check for sensor value jumps\n        return False\n\n    def is_actuator_faulty(self, control_outputs):\n        """Check for actuator anomalies"""\n        # Example: Check for excessive effort commands\n        return False\n\n    def is_behavior_unexpected(self, sensor_data):\n        """Check for unexpected robot behavior"""\n        # Example: Check for instability indicators\n        return False\n'})}),"\n",(0,o.jsx)(n.h2,{id:"real-time-performance-considerations",children:"Real-time Performance Considerations"}),"\n",(0,o.jsx)(n.h3,{id:"timing-analysis",children:"Timing Analysis"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import time\nfrom collections import deque\n\nclass TimingAnalyzer:\n    def __init__(self, window_size=100):\n        self.execution_times = deque(maxlen=window_size)\n        self.period_times = deque(maxlen=window_size)\n        self.deadline_misses = 0\n        self.target_period = 0.01  # 10ms for 100Hz control\n\n    def start_timing(self):\n        """Start timing measurement"""\n        self.start_time = time.time()\n\n    def stop_timing(self):\n        """Stop timing measurement and record results"""\n        end_time = time.time()\n        execution_time = end_time - self.start_time\n        period_time = end_time - getattr(self, \'last_end_time\', end_time)\n\n        self.execution_times.append(execution_time)\n        self.period_times.append(period_time)\n\n        if execution_time > self.target_period:\n            self.deadline_misses += 1\n\n        self.last_end_time = end_time\n\n    def get_statistics(self):\n        """Get timing performance statistics"""\n        if not self.execution_times:\n            return {}\n\n        avg_exec_time = sum(self.execution_times) / len(self.execution_times)\n        max_exec_time = max(self.execution_times)\n        min_exec_time = min(self.execution_times)\n\n        avg_period = sum(self.period_times) / len(self.period_times)\n\n        return {\n            \'avg_execution_time\': avg_exec_time,\n            \'max_execution_time\': max_exec_time,\n            \'min_execution_time\': min_exec_time,\n            \'avg_period\': avg_period,\n            \'deadline_misses\': self.deadline_misses,\n            \'utilization\': avg_exec_time / self.target_period\n        }\n'})}),"\n",(0,o.jsx)(n.h3,{id:"priority-based-scheduling",children:"Priority-Based Scheduling"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import heapq\nimport threading\nfrom dataclasses import dataclass, field\nfrom typing import Any\n\n@dataclass\nclass ControlTask:\n    priority: int\n    execution_time: float\n    deadline: float\n    function: callable\n    args: tuple = field(default_factory=tuple)\n    kwargs: dict = field(default_factory=dict)\n    task_id: str = ""\n\nclass PriorityScheduler:\n    def __init__(self):\n        self.task_queue = []\n        self.running = True\n        self.scheduler_thread = threading.Thread(target=self.run_scheduler)\n        self.scheduler_thread.start()\n\n    def add_task(self, task: ControlTask):\n        """Add a task to the priority queue"""\n        heapq.heappush(self.task_queue, (task.priority, task))\n\n    def run_scheduler(self):\n        """Run the priority-based scheduler"""\n        while self.running:\n            if self.task_queue:\n                priority, task = heapq.heappop(self.task_queue)\n\n                # Check if task has missed its deadline\n                if time.time() > task.deadline:\n                    print(f"Task {task.task_id} missed deadline")\n                    continue\n\n                # Execute task\n                try:\n                    task.function(*task.args, **task.kwargs)\n                except Exception as e:\n                    print(f"Task {task.task_id} execution failed: {e}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-control-architecture",children:"ROS 2 Control Architecture"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy\nfrom control_msgs.msg import JointTrajectoryControllerState\nfrom sensor_msgs.msg import JointState\nfrom trajectory_msgs.msg import JointTrajectory\nfrom std_msgs.msg import String\nimport threading\n\nclass ROS2ControlPipeline(Node):\n    def __init__(self):\n        super().__init__(\'control_pipeline\')\n\n        # QoS profiles for different types of data\n        sensor_qos = QoSProfile(\n            depth=10,\n            reliability=ReliabilityPolicy.BEST_EFFORT\n        )\n\n        control_qos = QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE\n        )\n\n        # Publishers and subscribers\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            sensor_qos\n        )\n\n        self.controller_state_sub = self.create_subscription(\n            JointTrajectoryControllerState,\n            \'/controller_state\',\n            self.controller_state_callback,\n            control_qos\n        )\n\n        self.trajectory_pub = self.create_publisher(\n            JointTrajectory,\n            \'/joint_trajectory_controller/joint_trajectory\',\n            control_qos\n        )\n\n        self.status_pub = self.create_publisher(\n            String,\n            \'/control_status\',\n            10\n        )\n\n        # Control pipeline threads\n        self.control_thread = threading.Thread(target=self.control_loop)\n        self.perception_thread = threading.Thread(target=self.perception_loop)\n\n        self.running = True\n        self.current_state = None\n        self.desired_trajectory = None\n\n        # Start threads\n        self.control_thread.start()\n        self.perception_thread.start()\n\n    def joint_state_callback(self, msg):\n        """Handle incoming joint state messages"""\n        self.current_state = msg\n\n    def controller_state_callback(self, msg):\n        """Handle controller state messages"""\n        # Update internal state based on controller feedback\n        pass\n\n    def control_loop(self):\n        """Main control loop running in separate thread"""\n        rate = self.create_rate(100)  # 100Hz\n        while self.running and rclpy.ok():\n            if self.current_state and self.desired_trajectory:\n                # Execute control algorithm\n                commands = self.compute_control_commands()\n                self.trajectory_pub.publish(commands)\n            rate.sleep()\n\n    def perception_loop(self):\n        """Perception processing loop"""\n        rate = self.create_rate(30)  # 30Hz for perception\n        while self.running and rclpy.ok():\n            # Process sensor data and update world model\n            self.process_perception_data()\n            rate.sleep()\n\n    def compute_control_commands(self):\n        """Compute control commands based on current state and desired trajectory"""\n        # Implement control algorithm\n        trajectory = JointTrajectory()\n        # ... populate trajectory message\n        return trajectory\n\n    def process_perception_data(self):\n        """Process sensor data for state estimation and environment understanding"""\n        # Implement perception processing\n        pass\n'})}),"\n",(0,o.jsx)(n.h2,{id:"practical-applications-in-humanoid-robotics",children:"Practical Applications in Humanoid Robotics"}),"\n",(0,o.jsx)(n.h3,{id:"walking-control-pipeline",children:"Walking Control Pipeline"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class WalkingController:\n    def __init__(self):\n        self.footstep_planner = FootstepPlanner()\n        self.trajectory_generator = WalkingTrajectoryGenerator()\n        self.balance_controller = BalanceController()\n        self.state_estimator = StateEstimator()\n\n        # Walking states\n        self.current_step = 0\n        self.support_foot = \'left\'\n        self.walking_state = \'stance\'\n\n    def update_walking(self, robot_state, walk_command):\n        """Main walking control pipeline"""\n        # 1. State estimation\n        estimated_state = self.state_estimator.estimate(robot_state)\n\n        # 2. Footstep planning (if needed)\n        if self.should_plan_footsteps(walk_command):\n            footsteps = self.footstep_planner.plan(\n                walk_command,\n                estimated_state[\'position\'],\n                estimated_state[\'orientation\']\n            )\n\n        # 3. Trajectory generation\n        walking_trajectory = self.trajectory_generator.generate(\n            footsteps,\n            estimated_state,\n            self.current_step\n        )\n\n        # 4. Balance control\n        balance_commands = self.balance_controller.compute(\n            walking_trajectory,\n            estimated_state\n        )\n\n        # 5. Output to joint controllers\n        return balance_commands\n\n    def should_plan_footsteps(self, command):\n        """Determine if new footsteps need to be planned"""\n        # Logic to determine if replanning is needed\n        return False\n'})}),"\n",(0,o.jsx)(n.h3,{id:"manipulation-control-pipeline",children:"Manipulation Control Pipeline"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class ManipulationController:\n    def __init__(self):\n        self.ik_solver = InverseKinematicsSolver()\n        self.trajectory_planner = TrajectoryPlanner()\n        self.grasp_planner = GraspPlanner()\n        self.force_controller = ForceController()\n\n    def execute_manipulation(self, task_description, robot_state):\n        \"\"\"Manipulation control pipeline\"\"\"\n        # 1. Task planning\n        grasp_pose = self.grasp_planner.plan_grasp(\n            task_description['object'],\n            task_description['goal']\n        )\n\n        # 2. Inverse kinematics\n        joint_trajectory = self.ik_solver.solve(\n            grasp_pose,\n            robot_state['end_effector_pose']\n        )\n\n        # 3. Trajectory optimization\n        optimized_trajectory = self.trajectory_planner.optimize(\n            joint_trajectory,\n            robot_state['obstacles']\n        )\n\n        # 4. Force control integration\n        force_commands = self.force_controller.compute(\n            optimized_trajectory,\n            expected_contact_points\n        )\n\n        return optimized_trajectory, force_commands\n"})}),"\n",(0,o.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsx)(n.h3,{id:"pipeline-parallelization",children:"Pipeline Parallelization"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import concurrent.futures\nimport queue\nimport threading\n\nclass ParallelControlPipeline:\n    def __init__(self, num_threads=4):\n        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=num_threads)\n        self.input_queue = queue.Queue()\n        self.output_queue = queue.Queue()\n        self.components = []\n        self.running = True\n\n    def add_component(self, component):\n        """Add a processing component to the pipeline"""\n        self.components.append(component)\n\n    def process_pipeline(self, input_data):\n        """Process data through all pipeline components in parallel where possible"""\n        # Submit independent components in parallel\n        futures = []\n        for component in self.components:\n            future = self.executor.submit(component.update, input_data)\n            futures.append(future)\n\n        # Collect results\n        results = []\n        for future in concurrent.futures.as_completed(futures):\n            results.append(future.result())\n\n        return results\n'})}),"\n",(0,o.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom collections import deque\n\nclass MemoryEfficientController:\n    def __init__(self, buffer_size=1000):\n        # Pre-allocate arrays to avoid memory allocation during control\n        self.position_buffer = np.zeros((buffer_size, 20))  # 20 joints\n        self.velocity_buffer = np.zeros((buffer_size, 20))\n        self.command_buffer = np.zeros((buffer_size, 20))\n\n        self.buffer_index = 0\n        self.buffer_size = buffer_size\n\n    def update_control(self, current_positions, current_velocities):\n        """Memory-efficient control update"""\n        # Use pre-allocated arrays\n        self.position_buffer[self.buffer_index] = current_positions\n        self.velocity_buffer[self.buffer_index] = current_velocities\n\n        # Compute control commands\n        commands = self.compute_efficient_control(\n            self.position_buffer[self.buffer_index],\n            self.velocity_buffer[self.buffer_index]\n        )\n\n        self.command_buffer[self.buffer_index] = commands\n\n        # Update buffer index\n        self.buffer_index = (self.buffer_index + 1) % self.buffer_size\n\n        return commands\n'})}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"Robot control pipelines provide the architectural foundation for humanoid robots, organizing the complex flow of information from perception to action through hierarchical control layers. Each layer operates at different temporal and spatial scales, with appropriate feedback mechanisms and safety considerations. Understanding these architectural patterns is crucial for developing robust Physical AI systems that can operate safely and effectively in real-world environments."}),"\n",(0,o.jsx)(n.p,{children:"The integration of safety mechanisms, real-time performance considerations, and ROS 2's distributed architecture enables the development of sophisticated humanoid control systems that can handle the complexity and demands of physical interaction with the environment. Proper pipeline design ensures that humanoid robots can perceive, reason, and act in a coordinated and reliable manner."}),"\n",(0,o.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'"Robotics: Control, Sensing, Vision, and Intelligence" by Fu, Gonzalez, and Lee'}),"\n",(0,o.jsx)(n.li,{children:'"Handbook of Robotics" edited by Siciliano and Khatib'}),"\n",(0,o.jsx)(n.li,{children:'"Planning Algorithms" by LaValle'}),"\n",(0,o.jsx)(n.li,{children:'"Probabilistic Robotics" by Thrun, Burgard, and Fox'}),"\n",(0,o.jsxs)(n.li,{children:["ROS 2 Control Documentation: ",(0,o.jsx)(n.a,{href:"https://control.ros.org/",children:"https://control.ros.org/"})]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>a});var o=t(6540);const i={},r=o.createContext(i);function s(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);