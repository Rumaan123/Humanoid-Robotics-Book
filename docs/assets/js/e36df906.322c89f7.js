"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[136],{1696(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var i=t(4848),o=t(8453);const a={sidebar_position:7},r="Visualization and Interaction using Unity: Advanced 3D Rendering for Physical AI",s={id:"module-2/unity-visualization",title:"Visualization and Interaction using Unity: Advanced 3D Rendering for Physical AI",description:"Overview",source:"@site/docs/module-2/unity-visualization.md",sourceDirName:"module-2",slug:"/module-2/unity-visualization",permalink:"/Humanoid-Robotics-Book/docs/module-2/unity-visualization",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Sensor Simulation: LiDAR, Depth Cameras, and IMUs for Physical AI Systems",permalink:"/Humanoid-Robotics-Book/docs/module-2/sensor-simulation"},next:{title:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)",permalink:"/Humanoid-Robotics-Book/docs/module-3/"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Unity&#39;s Role in Robotics Visualization",id:"unitys-role-in-robotics-visualization",level:3},{value:"Unity vs. Traditional Robotics Simulators",id:"unity-vs-traditional-robotics-simulators",level:3},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Unity Installation and ROS Integration",id:"unity-installation-and-ros-integration",level:3},{value:"Unity Robotics Hub Setup",id:"unity-robotics-hub-setup",level:3},{value:"Robot Model Integration",id:"robot-model-integration",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Animation and Control Systems",id:"animation-and-control-systems",level:3},{value:"Environment Creation and Management",id:"environment-creation-and-management",level:2},{value:"Procedural Environment Generation",id:"procedural-environment-generation",level:3},{value:"Dynamic Environment Interaction",id:"dynamic-environment-interaction",level:3},{value:"Sensor Visualization",id:"sensor-visualization",level:2},{value:"LiDAR Point Cloud Rendering",id:"lidar-point-cloud-rendering",level:3},{value:"Camera Feed Integration",id:"camera-feed-integration",level:3},{value:"Interaction Systems",id:"interaction-systems",level:2},{value:"VR/AR Integration",id:"vrar-integration",level:3},{value:"UI and Control Panels",id:"ui-and-control-panels",level:3},{value:"Advanced Rendering Techniques",id:"advanced-rendering-techniques",level:2},{value:"Realistic Lighting and Shading",id:"realistic-lighting-and-shading",level:3},{value:"Multi-Agent Visualization",id:"multi-agent-visualization",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"ROS 2 Communication in Unity",id:"ros-2-communication-in-unity",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Rendering Optimization",id:"rendering-optimization",level:3},{value:"Practical Applications in Humanoid Robotics",id:"practical-applications-in-humanoid-robotics",level:2},{value:"Teleoperation Interface",id:"teleoperation-interface",level:3},{value:"Training Environment",id:"training-environment",level:3},{value:"Best Practices for Unity Robotics",id:"best-practices-for-unity-robotics",level:2},{value:"Architecture and Design Patterns",id:"architecture-and-design-patterns",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"visualization-and-interaction-using-unity-advanced-3d-rendering-for-physical-ai",children:"Visualization and Interaction using Unity: Advanced 3D Rendering for Physical AI"}),"\n",(0,i.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(e.p,{children:"Unity has emerged as a powerful platform for advanced visualization and interaction in Physical AI systems, offering high-fidelity 3D rendering capabilities, realistic physics simulation, and sophisticated user interaction mechanisms. In the context of humanoid robotics and digital twins, Unity provides an alternative or complementary visualization environment to traditional robotics simulators, enabling photorealistic rendering, immersive human-robot interaction, and complex multi-agent simulations. The platform's extensive asset ecosystem, real-time rendering capabilities, and cross-platform deployment options make it particularly valuable for creating engaging and informative visualization interfaces for robotic systems."}),"\n",(0,i.jsx)(e.p,{children:"Unity's integration with ROS 2 through specialized packages enables seamless data exchange between robotic systems and visualization environments, allowing real-time display of robot states, sensor data, and environmental information. This integration is crucial for developing intuitive interfaces that support robot monitoring, teleoperation, and immersive training environments for Physical AI systems."}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this section, you should be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Integrate Unity as a visualization and interaction platform"}),"\n",(0,i.jsx)(e.li,{children:"Implement realistic rendering for robot and environment visualization"}),"\n",(0,i.jsx)(e.li,{children:"Create interactive interfaces for robot teleoperation and monitoring"}),"\n",(0,i.jsx)(e.li,{children:"Connect Unity visualization with ROS 2 simulation systems"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"unitys-role-in-robotics-visualization",children:"Unity's Role in Robotics Visualization"}),"\n",(0,i.jsx)(e.p,{children:"Unity serves multiple roles in robotics and Physical AI:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Photorealistic Rendering"}),": High-quality visualization for perception training and realistic simulation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Human-Robot Interaction"}),": Intuitive interfaces for robot control and monitoring"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Training Environments"}),": Safe, controllable environments for AI development"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-Agent Simulation"}),": Complex scenarios with multiple interacting agents"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Virtual Reality Integration"}),": Immersive environments for teleoperation and training"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"unity-vs-traditional-robotics-simulators",children:"Unity vs. Traditional Robotics Simulators"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Aspect"}),(0,i.jsx)(e.th,{children:"Unity"}),(0,i.jsx)(e.th,{children:"Traditional Robotics Simulators (Gazebo, etc.)"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Visual Quality"}),(0,i.jsx)(e.td,{children:"Photorealistic"}),(0,i.jsx)(e.td,{children:"Functional/Technical"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Rendering Performance"}),(0,i.jsx)(e.td,{children:"GPU-intensive"}),(0,i.jsx)(e.td,{children:"CPU-based physics focus"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Interaction Model"}),(0,i.jsx)(e.td,{children:"Game engine paradigm"}),(0,i.jsx)(e.td,{children:"Robotics-specific"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Asset Library"}),(0,i.jsx)(e.td,{children:"Extensive marketplace"}),(0,i.jsx)(e.td,{children:"Limited robotics models"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Physics Engine"}),(0,i.jsx)(e.td,{children:"Built-in (Unity Physics)"}),(0,i.jsx)(e.td,{children:"Specialized (ODE, Bullet)"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Target Use"}),(0,i.jsx)(e.td,{children:"Visualization, interaction"}),(0,i.jsx)(e.td,{children:"Simulation, testing"})]})]})]}),"\n",(0,i.jsx)(e.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"unity-installation-and-ros-integration",children:"Unity Installation and ROS Integration"}),"\n",(0,i.jsx)(e.p,{children:"To set up Unity for robotics applications, you'll need:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Unity Hub and Editor"}),": Download from Unity's official website"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"ROS# Package"}),": For ROS communication"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Unity Robotics Package"}),": Official Unity robotics tools"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Basic Unity ROS connection setup\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Std;\n\npublic class UnityROSBridge : MonoBehaviour\n{\n    private ROSConnection ros;\n\n    void Start()\n    {\n        // Get the ROS connection system\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Set the IP address of the ROS system\n        ros.Initialize("127.0.0.1", 10000);\n\n        // Subscribe to ROS topics\n        ros.Subscribe<UInt8Msg>("robot_mode", OnRobotModeReceived);\n    }\n\n    void OnRobotModeReceived(UInt8Msg robotMode)\n    {\n        Debug.Log("Robot mode received: " + robotMode.data);\n        // Handle robot mode change\n    }\n\n    void Update()\n    {\n        // Publish messages at regular intervals\n        if (Time.time % 1.0f < Time.deltaTime) // Every second\n        {\n            var message = new UInt8Msg();\n            message.data = 1; // Example data\n            ros.Publish("unity_status", message);\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"unity-robotics-hub-setup",children:"Unity Robotics Hub Setup"}),"\n",(0,i.jsx)(e.p,{children:"The Unity Robotics Hub provides essential tools for robotics development:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Robot control interface in Unity\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\nusing RosMessageTypes.Geometry;\n\npublic class RobotController : MonoBehaviour\n{\n    [SerializeField] private string jointStateTopic = "/joint_states";\n    [SerializeField] private string cmdVelTopic = "/cmd_vel";\n\n    private ROSConnection ros;\n    private JointStateMsg lastJointState;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Subscribe<JointStateMsg>(jointStateTopic, OnJointStateReceived);\n    }\n\n    void OnJointStateReceived(JointStateMsg jointState)\n    {\n        lastJointState = jointState;\n        UpdateRobotVisualization();\n    }\n\n    void UpdateRobotVisualization()\n    {\n        if (lastJointState == null) return;\n\n        // Update joint positions in Unity\n        for (int i = 0; i < lastJointState.name.Count; i++)\n        {\n            string jointName = lastJointState.name[i];\n            float jointPosition = (float)lastJointState.position[i];\n\n            Transform jointTransform = FindJointByName(jointName);\n            if (jointTransform != null)\n            {\n                // Update joint rotation based on received position\n                jointTransform.localRotation = Quaternion.Euler(0, jointPosition * Mathf.Rad2Deg, 0);\n            }\n        }\n    }\n\n    Transform FindJointByName(string name)\n    {\n        // Find the corresponding joint in the Unity hierarchy\n        Transform[] allChildren = GetComponentsInChildren<Transform>();\n        foreach (Transform child in allChildren)\n        {\n            if (child.name == name)\n                return child;\n        }\n        return null;\n    }\n\n    public void SendVelocityCommand(float linearX, float angularZ)\n    {\n        var cmd = new TwistMsg();\n        cmd.linear = new Vector3Msg(linearX, 0, 0);\n        cmd.angular = new Vector3Msg(0, 0, angularZ);\n\n        ros.Publish(cmdVelTopic, cmd);\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"robot-model-integration",children:"Robot Model Integration"}),"\n",(0,i.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,i.jsx)(e.p,{children:"Unity can import robot models in various formats, with FBX being the most common:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:"// Example: Robot model importer and animator\nusing UnityEngine;\n\npublic class RobotModelImporter : MonoBehaviour\n{\n    [System.Serializable]\n    public class JointMapping\n    {\n        public string rosJointName;\n        public Transform unityJoint;\n        public JointType jointType;\n        public float minAngle;\n        public float maxAngle;\n    }\n\n    public enum JointType\n    {\n        Revolute,\n        Prismatic,\n        Fixed\n    }\n\n    public JointMapping[] jointMappings;\n\n    void Start()\n    {\n        SetupJointConstraints();\n    }\n\n    void SetupJointConstraints()\n    {\n        foreach (var mapping in jointMappings)\n        {\n            if (mapping.jointType == JointType.Revolute)\n            {\n                // Add hinge joint constraints if needed\n                ConfigurableJoint joint = mapping.unityJoint.GetComponent<ConfigurableJoint>();\n                if (joint != null)\n                {\n                    joint.lowAngularXLimit = mapping.minAngle;\n                    joint.highAngularXLimit = mapping.maxAngle;\n                }\n            }\n        }\n    }\n\n    public void UpdateJointPositions(float[] positions)\n    {\n        for (int i = 0; i < jointMappings.Length && i < positions.Length; i++)\n        {\n            JointMapping mapping = jointMappings[i];\n            float position = positions[i];\n\n            switch (mapping.jointType)\n            {\n                case JointType.Revolute:\n                    mapping.unityJoint.localRotation =\n                        Quaternion.Euler(0, position * Mathf.Rad2Deg, 0);\n                    break;\n                case JointType.Prismatic:\n                    mapping.unityJoint.localPosition =\n                        new Vector3(position, 0, 0);\n                    break;\n            }\n        }\n    }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"animation-and-control-systems",children:"Animation and Control Systems"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Advanced robot animation controller\nusing UnityEngine;\nusing UnityEngine.Animations;\n\npublic class RobotAnimationController : MonoBehaviour\n{\n    [Header("Animation Parameters")]\n    public Animator animator;\n    public AnimationCurve walkCycle;\n    public AnimationCurve balanceCorrection;\n\n    [Header("IK Settings")]\n    public bool useFootIK = true;\n    public Transform leftFootTarget;\n    public Transform rightFootTarget;\n\n    private float animationSpeed = 1.0f;\n    private bool isWalking = false;\n    private bool isBalancing = false;\n\n    void Start()\n    {\n        if (animator == null)\n            animator = GetComponent<Animator>();\n    }\n\n    void OnAnimatorIK(int layerIndex)\n    {\n        if (!useFootIK) return;\n\n        // Left foot IK\n        if (leftFootTarget != null)\n        {\n            animator.SetIKPositionWeight(AvatarIKGoal.LeftFoot, 1.0f);\n            animator.SetIKPosition(AvatarIKGoal.LeftFoot, leftFootTarget.position);\n        }\n\n        // Right foot IK\n        if (rightFootTarget != null)\n        {\n            animator.SetIKPositionWeight(AvatarIKGoal.RightFoot, 1.0f);\n            animator.SetIKPosition(AvatarIKGoal.RightFoot, rightFootTarget.position);\n        }\n    }\n\n    public void SetWalking(bool walking)\n    {\n        isWalking = walking;\n        animator.SetBool("IsWalking", walking);\n    }\n\n    public void SetBalanceCorrection(float correction)\n    {\n        isBalancing = Mathf.Abs(correction) > 0.1f;\n        animator.SetFloat("BalanceCorrection", correction);\n    }\n\n    void Update()\n    {\n        // Update animation parameters based on robot state\n        animator.SetFloat("Speed", animationSpeed);\n        animator.SetBool("IsBalancing", isBalancing);\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"environment-creation-and-management",children:"Environment Creation and Management"}),"\n",(0,i.jsx)(e.h3,{id:"procedural-environment-generation",children:"Procedural Environment Generation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Procedural environment generation for robotics training\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class ProceduralEnvironmentGenerator : MonoBehaviour\n{\n    [System.Serializable]\n    public class EnvironmentPrefab\n    {\n        public GameObject prefab;\n        public int minCount;\n        public int maxCount;\n        public Bounds spawnBounds;\n        public float minScale = 0.8f;\n        public float maxScale = 1.2f;\n    }\n\n    public EnvironmentPrefab[] environmentPrefabs;\n    public Transform environmentRoot;\n\n    [Header("Terrain Settings")]\n    public int terrainWidth = 100;\n    public int terrainHeight = 100;\n    public float terrainScale = 1.0f;\n\n    private List<GameObject> spawnedObjects = new List<GameObject>();\n\n    public void GenerateEnvironment()\n    {\n        ClearEnvironment();\n\n        // Generate terrain\n        GenerateTerrain();\n\n        // Spawn environment objects\n        foreach (var prefabData in environmentPrefabs)\n        {\n            int count = Random.Range(prefabData.minCount, prefabData.maxCount + 1);\n\n            for (int i = 0; i < count; i++)\n            {\n                SpawnEnvironmentObject(prefabData);\n            }\n        }\n    }\n\n    void GenerateTerrain()\n    {\n        // Create terrain programmatically\n        Terrain terrain = Terrain.activeTerrain;\n        if (terrain == null)\n        {\n            GameObject terrainObj = new GameObject("ProceduralTerrain");\n            terrain = terrainObj.AddComponent<Terrain>();\n            terrain.terrainData = new TerrainData();\n        }\n\n        // Set terrain size\n        terrain.terrainData.size = new Vector3(terrainWidth, 10, terrainHeight);\n\n        // Generate heightmap\n        int resolution = terrain.terrainData.heightmapResolution;\n        float[,] heights = new float[resolution, resolution];\n\n        for (int x = 0; x < resolution; x++)\n        {\n            for (int y = 0; y < resolution; y++)\n            {\n                float xCoord = (float)x / resolution * terrainScale;\n                float yCoord = (float)y / resolution * terrainScale;\n\n                // Generate terrain height using noise\n                heights[x, y] = Mathf.PerlinNoise(xCoord, yCoord) * 0.1f;\n            }\n        }\n\n        terrain.terrainData.SetHeights(0, 0, heights);\n    }\n\n    void SpawnEnvironmentObject(EnvironmentPrefab prefabData)\n    {\n        Vector3 spawnPosition = new Vector3(\n            Random.Range(prefabData.spawnBounds.min.x, prefabData.spawnBounds.max.x),\n            prefabData.spawnBounds.min.y,\n            Random.Range(prefabData.spawnBounds.min.z, prefabData.spawnBounds.max.z)\n        );\n\n        GameObject spawnedObject = Instantiate(\n            prefabData.prefab,\n            spawnPosition,\n            Quaternion.Euler(0, Random.Range(0, 360), 0),\n            environmentRoot\n        );\n\n        // Random scaling\n        float scale = Random.Range(prefabData.minScale, prefabData.maxScale);\n        spawnedObject.transform.localScale = Vector3.one * scale;\n\n        spawnedObjects.Add(spawnedObject);\n    }\n\n    void ClearEnvironment()\n    {\n        foreach (GameObject obj in spawnedObjects)\n        {\n            if (obj != null)\n                DestroyImmediate(obj);\n        }\n        spawnedObjects.Clear();\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"dynamic-environment-interaction",children:"Dynamic Environment Interaction"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Physics-based environment interaction\nusing UnityEngine;\n\npublic class EnvironmentInteraction : MonoBehaviour\n{\n    [Header("Interaction Settings")]\n    public float interactionDistance = 3.0f;\n    public LayerMask interactionLayers;\n\n    [Header("Physics Settings")]\n    public float pushForce = 10.0f;\n    public float grabDistance = 2.0f;\n\n    private Camera mainCamera;\n    private GameObject grabbedObject;\n    private FixedJoint grabJoint;\n\n    void Start()\n    {\n        mainCamera = Camera.main;\n    }\n\n    void Update()\n    {\n        HandleInteractionInput();\n    }\n\n    void HandleInteractionInput()\n    {\n        // Raycast for interaction\n        Ray ray = mainCamera.ScreenPointToRay(Input.mousePosition);\n        RaycastHit hit;\n\n        if (Physics.Raycast(ray, out hit, interactionDistance, interactionLayers))\n        {\n            GameObject target = hit.collider.gameObject;\n\n            if (Input.GetKeyDown(KeyCode.E))\n            {\n                // Grab object\n                GrabObject(target, hit.point);\n            }\n            else if (Input.GetKeyDown(KeyCode.F))\n            {\n                // Push object\n                PushObject(target, hit.normal);\n            }\n        }\n\n        // Update grabbed object position\n        if (grabbedObject != null && grabJoint == null)\n        {\n            // Move object with mouse\n            Ray rayToObj = mainCamera.ScreenPointToRay(Input.mousePosition);\n            Vector3 targetPosition = rayToObj.GetPoint(grabDistance);\n            grabbedObject.transform.position = Vector3.Lerp(\n                grabbedObject.transform.position,\n                targetPosition,\n                Time.deltaTime * 10f\n            );\n        }\n    }\n\n    void GrabObject(GameObject obj, Vector3 hitPoint)\n    {\n        Rigidbody rb = obj.GetComponent<Rigidbody>();\n        if (rb != null)\n        {\n            grabbedObject = obj;\n\n            // Create fixed joint for grabbing\n            grabJoint = obj.AddComponent<FixedJoint>();\n            grabJoint.connectedBody = this.GetComponent<Rigidbody>();\n        }\n    }\n\n    void PushObject(GameObject obj, Vector3 normal)\n    {\n        Rigidbody rb = obj.GetComponent<Rigidbody>();\n        if (rb != null)\n        {\n            Vector3 pushDirection = normal * pushForce;\n            rb.AddForce(pushDirection, ForceMode.Impulse);\n        }\n    }\n\n    public void ReleaseObject()\n    {\n        if (grabbedObject != null)\n        {\n            if (grabJoint != null)\n            {\n                DestroyImmediate(grabJoint);\n            }\n            grabbedObject = null;\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"sensor-visualization",children:"Sensor Visualization"}),"\n",(0,i.jsx)(e.h3,{id:"lidar-point-cloud-rendering",children:"LiDAR Point Cloud Rendering"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Real-time LiDAR point cloud visualization\nusing UnityEngine;\nusing System.Collections.Generic;\n\n[RequireComponent(typeof(PointCloudRenderer))]\npublic class LidarPointCloudVisualizer : MonoBehaviour\n{\n    [Header("Point Cloud Settings")]\n    public Material pointMaterial;\n    public float pointSize = 0.02f;\n    public Color pointColor = Color.green;\n\n    [Header("Performance Settings")]\n    public int maxPoints = 100000;\n    public float updateRate = 30.0f; // Hz\n\n    private PointCloudRenderer pointCloudRenderer;\n    private List<Vector3> points = new List<Vector3>();\n    private List<Color> colors = new List<Color>();\n    private float lastUpdateTime;\n\n    void Start()\n    {\n        pointCloudRenderer = GetComponent<PointCloudRenderer>();\n        if (pointCloudRenderer == null)\n        {\n            pointCloudRenderer = gameObject.AddComponent<PointCloudRenderer>();\n        }\n\n        // Create material if not assigned\n        if (pointMaterial == null)\n        {\n            pointMaterial = new Material(Shader.Find("Sprites/Default"));\n            pointMaterial.color = pointColor;\n        }\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= 1.0f / updateRate)\n        {\n            UpdatePointCloud();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    public void AddLidarScan(float[] ranges, float[] intensities, float angleMin, float angleIncrement)\n    {\n        points.Clear();\n        colors.Clear();\n\n        for (int i = 0; i < ranges.Length && points.Count < maxPoints; i++)\n        {\n            float range = ranges[i];\n            if (range > 0 && range < 30.0f) // Valid range\n            {\n                float angle = angleMin + i * angleIncrement;\n\n                Vector3 point = new Vector3(\n                    range * Mathf.Cos(angle),\n                    0, // Assuming 2D LiDAR\n                    range * Mathf.Sin(angle)\n                );\n\n                points.Add(point);\n\n                // Color based on intensity or distance\n                float intensity = intensities != null && i < intensities.Length ? intensities[i] : 1.0f;\n                Color pointColor = Color.Lerp(Color.red, Color.green, intensity / 255.0f);\n                colors.Add(pointColor);\n            }\n        }\n\n        // Update renderer with new points\n        pointCloudRenderer.UpdatePointCloud(points, colors, pointSize);\n    }\n\n    public void Add3DLidarScan(Vector3[] pointCloud)\n    {\n        points.Clear();\n        colors.Clear();\n\n        for (int i = 0; i < Mathf.Min(pointCloud.Length, maxPoints); i++)\n        {\n            points.Add(pointCloud[i]);\n            colors.Add(pointColor);\n        }\n\n        pointCloudRenderer.UpdatePointCloud(points, colors, pointSize);\n    }\n}\n\n// Custom point cloud renderer\npublic class PointCloudRenderer : MonoBehaviour\n{\n    private GameObject[] pointObjects;\n    private Material pointMaterial;\n\n    public void UpdatePointCloud(List<Vector3> points, List<Color> colors, float pointSize)\n    {\n        // Ensure we have enough point objects\n        if (pointObjects == null || pointObjects.Length != points.Count)\n        {\n            ClearPoints();\n            CreatePoints(points.Count);\n        }\n\n        // Update positions and colors\n        for (int i = 0; i < points.Count; i++)\n        {\n            if (pointObjects[i] != null)\n            {\n                pointObjects[i].transform.position = transform.position + points[i];\n                pointObjects[i].transform.localScale = Vector3.one * pointSize;\n\n                // Update color (this is a simplified approach)\n                Renderer renderer = pointObjects[i].GetComponent<Renderer>();\n                if (renderer != null && i < colors.Count)\n                {\n                    renderer.material.color = colors[i];\n                }\n            }\n        }\n\n        // Hide extra points\n        for (int i = points.Count; i < pointObjects.Length; i++)\n        {\n            if (pointObjects[i] != null)\n            {\n                pointObjects[i].SetActive(false);\n            }\n        }\n    }\n\n    void CreatePoints(int count)\n    {\n        pointObjects = new GameObject[count];\n        for (int i = 0; i < count; i++)\n        {\n            pointObjects[i] = GameObject.CreatePrimitive(PrimitiveType.Sphere);\n            pointObjects[i].transform.SetParent(transform);\n            pointObjects[i].SetActive(false);\n\n            // Remove collider for performance\n            DestroyImmediate(pointObjects[i].GetComponent<Collider>());\n        }\n    }\n\n    void ClearPoints()\n    {\n        if (pointObjects != null)\n        {\n            foreach (GameObject point in pointObjects)\n            {\n                if (point != null)\n                    DestroyImmediate(point);\n            }\n            pointObjects = null;\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"camera-feed-integration",children:"Camera Feed Integration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Real-time camera feed visualization\nusing UnityEngine;\nusing UnityEngine.UI;\nusing System.Threading.Tasks;\n\npublic class CameraFeedVisualizer : MonoBehaviour\n{\n    [Header("Camera Settings")]\n    public RawImage cameraDisplay;\n    public int cameraWidth = 640;\n    public int cameraHeight = 480;\n    public int cameraFps = 30;\n\n    [Header("ROS Integration")]\n    public string imageTopic = "/camera/color/image_raw";\n\n    private Texture2D cameraTexture;\n    private byte[] imageBuffer;\n\n    void Start()\n    {\n        InitializeCameraTexture();\n        SubscribeToCameraTopic();\n    }\n\n    void InitializeCameraTexture()\n    {\n        cameraTexture = new Texture2D(cameraWidth, cameraHeight, TextureFormat.RGB24, false);\n        if (cameraDisplay != null)\n        {\n            cameraDisplay.texture = cameraTexture;\n        }\n    }\n\n    void SubscribeToCameraTopic()\n    {\n        // Subscribe to ROS image topic\n        ROSConnection.GetOrCreateInstance()\n            .Subscribe<RosMessageTypes.Sensor.ImageMsg>(\n                imageTopic,\n                OnImageReceived\n            );\n    }\n\n    void OnImageReceived(RosMessageTypes.Sensor.ImageMsg imageMsg)\n    {\n        if (imageMsg.encoding == "rgb8" || imageMsg.encoding == "bgr8")\n        {\n            // Decode image data\n            UpdateCameraTexture(imageMsg.data);\n        }\n    }\n\n    void UpdateCameraTexture(byte[] imageData)\n    {\n        // Handle different encodings\n        if (imageData.Length == cameraWidth * cameraHeight * 3)\n        {\n            // Direct RGB/BGR data\n            Color32[] colors = new Color32[imageData.Length / 3];\n\n            for (int i = 0; i < colors.Length; i++)\n            {\n                if (imageMsg.encoding == "bgr8")\n                {\n                    // Convert BGR to RGB\n                    byte r = imageData[i * 3 + 2];\n                    byte g = imageData[i * 3 + 1];\n                    byte b = imageData[i * 3 + 0];\n                    colors[i] = new Color32(r, g, b, 255);\n                }\n                else\n                {\n                    // RGB format\n                    colors[i] = new Color32(\n                        imageData[i * 3],\n                        imageData[i * 3 + 1],\n                        imageData[i * 3 + 2],\n                        255\n                    );\n                }\n            }\n\n            cameraTexture.SetPixels32(colors);\n            cameraTexture.Apply();\n        }\n    }\n\n    // Alternative method for depth camera visualization\n    public void UpdateDepthVisualization(float[,] depthData)\n    {\n        Color32[] depthColors = new Color32[depthData.GetLength(0) * depthData.GetLength(1)];\n\n        float maxDepth = 10.0f; // meters\n\n        for (int y = 0; y < depthData.GetLength(0); y++)\n        {\n            for (int x = 0; x < depthData.GetLength(1); x++)\n            {\n                float depth = depthData[y, x];\n                float normalizedDepth = Mathf.Clamp01(depth / maxDepth);\n\n                // Map depth to color gradient\n                Color depthColor = Color.Lerp(Color.black, Color.white, normalizedDepth);\n                depthColors[y * depthData.GetLength(1) + x] =\n                    new Color32(\n                        (byte)(depthColor.r * 255),\n                        (byte)(depthColor.g * 255),\n                        (byte)(depthColor.b * 255),\n                        255\n                    );\n            }\n        }\n\n        cameraTexture.SetPixels32(depthColors);\n        cameraTexture.Apply();\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"interaction-systems",children:"Interaction Systems"}),"\n",(0,i.jsx)(e.h3,{id:"vrar-integration",children:"VR/AR Integration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: VR interaction for robot teleoperation\nusing UnityEngine;\nusing UnityEngine.XR;\n\npublic class VRRobotController : MonoBehaviour\n{\n    [Header("VR Controller Setup")]\n    public XRNode controllerNode = XRNode.RightHand;\n    public Transform robotBase;\n\n    [Header("Teleoperation Settings")]\n    public float moveSpeed = 1.0f;\n    public float rotationSpeed = 50.0f;\n\n    [Header("Haptic Feedback")]\n    public bool enableHaptics = true;\n    public float hapticIntensity = 0.5f;\n\n    private InputDevice controller;\n    private Vector2 primaryAxis;\n    private bool triggerPressed = false;\n\n    void Start()\n    {\n        UpdateController();\n    }\n\n    void Update()\n    {\n        UpdateController();\n        HandleVRInput();\n        ApplyHapticFeedback();\n    }\n\n    void UpdateController()\n    {\n        var devices = new List<InputDevice>();\n        InputDevices.GetDevicesAtXRNode(controllerNode, devices);\n\n        if (devices.Count > 0)\n        {\n            controller = devices[0];\n        }\n    }\n\n    void HandleVRInput()\n    {\n        if (controller == null) return;\n\n        // Get thumbstick input for movement\n        controller.TryGetFeatureValue(CommonUsages.primary2DAxis, out primaryAxis);\n\n        // Get trigger input for actions\n        controller.TryGetFeatureValue(CommonUsages.triggerButton, out triggerPressed);\n\n        // Move robot based on thumbstick input\n        if (primaryAxis.magnitude > 0.1f)\n        {\n            Vector3 movement = new Vector3(primaryAxis.x, 0, primaryAxis.y);\n            robotBase.Translate(movement * moveSpeed * Time.deltaTime, Space.World);\n        }\n\n        // Rotate robot based on grip button\n        bool gripPressed = false;\n        controller.TryGetFeatureValue(CommonUsages.gripButton, out gripPressed);\n\n        if (gripPressed)\n        {\n            robotBase.Rotate(0, primaryAxis.x * rotationSpeed * Time.deltaTime, 0);\n        }\n    }\n\n    void ApplyHapticFeedback()\n    {\n        if (!enableHaptics || controller == null) return;\n\n        // Apply haptic feedback based on robot state\n        if (triggerPressed)\n        {\n            controller.SendHapticImpulse(0, hapticIntensity, 0.1f);\n        }\n    }\n\n    public void SetRobotControlled(bool controlled)\n    {\n        // Visual feedback for robot control state\n        Renderer[] renderers = robotBase.GetComponentsInChildren<Renderer>();\n        foreach (Renderer renderer in renderers)\n        {\n            Material mat = renderer.material;\n            if (controlled)\n            {\n                mat.SetColor("_EmissionColor", Color.green);\n            }\n            else\n            {\n                mat.SetColor("_EmissionColor", Color.black);\n            }\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"ui-and-control-panels",children:"UI and Control Panels"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Robot monitoring and control UI\nusing UnityEngine;\nusing UnityEngine.UI;\nusing System.Collections.Generic;\n\npublic class RobotControlPanel : MonoBehaviour\n{\n    [Header("UI References")]\n    public Text robotStatusText;\n    public Text batteryLevelText;\n    public Text jointPositionText;\n    public Slider speedSlider;\n    public Button emergencyStopButton;\n    public Toggle autoModeToggle;\n\n    [Header("Robot Data")]\n    public float maxBattery = 100.0f;\n    public float currentBattery = 85.0f;\n    public float[] jointPositions;\n    public float robotSpeed = 1.0f;\n\n    private bool emergencyStopActive = false;\n    private bool autoModeEnabled = false;\n\n    void Start()\n    {\n        InitializeUI();\n        SetupEventHandlers();\n    }\n\n    void InitializeUI()\n    {\n        speedSlider.minValue = 0.0f;\n        speedSlider.maxValue = 2.0f;\n        speedSlider.value = robotSpeed;\n\n        UpdateUI();\n    }\n\n    void SetupEventHandlers()\n    {\n        speedSlider.onValueChanged.AddListener(OnSpeedChanged);\n        emergencyStopButton.onClick.AddListener(OnEmergencyStop);\n        autoModeToggle.onValueChanged.AddListener(OnAutoModeChanged);\n    }\n\n    void Update()\n    {\n        UpdateRobotData();\n        UpdateUI();\n    }\n\n    void UpdateRobotData()\n    {\n        // Update from ROS or robot state\n        // This would typically come from ROS messages\n        currentBattery -= Time.deltaTime * 0.01f; // Simulate battery drain\n        if (currentBattery < 0) currentBattery = 0;\n    }\n\n    void UpdateUI()\n    {\n        robotStatusText.text = emergencyStopActive ? "EMERGENCY STOP" :\n                              autoModeEnabled ? "AUTO MODE" : "MANUAL";\n\n        batteryLevelText.text = $"Battery: {currentBattery:F1}%";\n\n        if (jointPositions != null && jointPositions.Length > 0)\n        {\n            string jointInfo = "Joints: ";\n            for (int i = 0; i < Mathf.Min(5, jointPositions.Length); i++)\n            {\n                jointInfo += $"J{i}:{jointPositions[i]:F2} ";\n            }\n            jointPositionText.text = jointInfo;\n        }\n\n        robotStatusText.color = emergencyStopActive ? Color.red :\n                               autoModeEnabled ? Color.blue : Color.white;\n    }\n\n    void OnSpeedChanged(float value)\n    {\n        robotSpeed = value;\n        // Send speed command to robot\n        SendSpeedCommand(robotSpeed);\n    }\n\n    void OnEmergencyStop()\n    {\n        emergencyStopActive = !emergencyStopActive;\n        if (emergencyStopActive)\n        {\n            SendEmergencyStopCommand();\n        }\n        else\n        {\n            SendResumeCommand();\n        }\n    }\n\n    void OnAutoModeChanged(bool isOn)\n    {\n        autoModeEnabled = isOn;\n        if (autoModeEnabled)\n        {\n            SendAutoModeCommand();\n        }\n        else\n        {\n            SendManualModeCommand();\n        }\n    }\n\n    void SendSpeedCommand(float speed)\n    {\n        // Send speed command via ROS\n        var cmd = new RosMessageTypes.Std.Float32Msg();\n        cmd.data = speed;\n        ROSConnection.GetOrCreateInstance().Publish("/robot_speed", cmd);\n    }\n\n    void SendEmergencyStopCommand()\n    {\n        var cmd = new RosMessageTypes.Std.BoolMsg();\n        cmd.data = true;\n        ROSConnection.GetOrCreateInstance().Publish("/emergency_stop", cmd);\n    }\n\n    void SendResumeCommand()\n    {\n        var cmd = new RosMessageTypes.Std.BoolMsg();\n        cmd.data = false;\n        ROSConnection.GetOrCreateInstance().Publish("/emergency_stop", cmd);\n    }\n\n    void SendAutoModeCommand()\n    {\n        var cmd = new RosMessageTypes.Std.StringMsg();\n        cmd.data = "auto";\n        ROSConnection.GetOrCreateInstance().Publish("/control_mode", cmd);\n    }\n\n    void SendManualModeCommand()\n    {\n        var cmd = new RosMessageTypes.Std.StringMsg();\n        cmd.data = "manual";\n        ROSConnection.GetOrCreateInstance().Publish("/control_mode", cmd);\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"advanced-rendering-techniques",children:"Advanced Rendering Techniques"}),"\n",(0,i.jsx)(e.h3,{id:"realistic-lighting-and-shading",children:"Realistic Lighting and Shading"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Advanced rendering for realistic robot visualization\nusing UnityEngine;\nusing UnityEngine.Rendering;\n\npublic class AdvancedRobotRenderer : MonoBehaviour\n{\n    [Header("Material Properties")]\n    public Material robotMaterial;\n    public Texture2D normalMap;\n    public Texture2D roughnessMap;\n    public Texture2D metallicMap;\n\n    [Header("Lighting Settings")]\n    public Light mainLight;\n    public float ambientIntensity = 0.3f;\n    public Color robotColor = Color.gray;\n\n    [Header("Post-Processing")]\n    public bool enableSSAO = true;\n    public bool enableBloom = true;\n\n    private Renderer robotRenderer;\n    private MaterialPropertyBlock materialProperties;\n\n    void Start()\n    {\n        robotRenderer = GetComponent<Renderer>();\n        materialProperties = new MaterialPropertyBlock();\n\n        SetupAdvancedRendering();\n    }\n\n    void SetupAdvancedRendering()\n    {\n        if (robotMaterial != null)\n        {\n            robotRenderer.material = robotMaterial;\n        }\n\n        // Set up material properties\n        materialProperties.SetColor("_BaseColor", robotColor);\n        materialProperties.SetTexture("_NormalMap", normalMap);\n        materialProperties.SetTexture("_MetallicGlossMap", metallicMap);\n        materialProperties.SetTexture("_BumpMap", roughnessMap);\n        materialProperties.SetFloat("_Metallic", 0.5f);\n        materialProperties.SetFloat("_Smoothness", 0.5f);\n\n        robotRenderer.SetPropertyBlock(materialProperties);\n\n        // Configure lighting\n        RenderSettings.ambientIntensity = ambientIntensity;\n    }\n\n    public void UpdateRobotAppearance(float wearLevel, Color damageColor)\n    {\n        // Update material based on robot condition\n        Color finalColor = Color.Lerp(robotColor, damageColor, wearLevel);\n        materialProperties.SetColor("_BaseColor", finalColor);\n\n        // Add wear and tear effects\n        materialProperties.SetFloat("_ScratchIntensity", wearLevel);\n        materialProperties.SetFloat("_DirtAmount", wearLevel * 0.5f);\n\n        robotRenderer.SetPropertyBlock(materialProperties);\n    }\n\n    public void SetRobotHighlight(bool highlighted)\n    {\n        if (highlighted)\n        {\n            materialProperties.SetColor("_EmissionColor", Color.yellow * 2f);\n            materialProperties.SetFloat("_EmissionIntensity", 1.0f);\n        }\n        else\n        {\n            materialProperties.SetColor("_EmissionColor", Color.black);\n            materialProperties.SetFloat("_EmissionIntensity", 0.0f);\n        }\n\n        robotRenderer.SetPropertyBlock(materialProperties);\n    }\n\n    // Custom shader for robot-specific effects\n    public void ApplyCustomShader()\n    {\n        Shader customShader = Shader.Find("Custom/RobotShader");\n        if (customShader != null)\n        {\n            robotRenderer.material.shader = customShader;\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"multi-agent-visualization",children:"Multi-Agent Visualization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Multi-agent robot visualization system\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class MultiAgentVisualization : MonoBehaviour\n{\n    [Header("Agent Settings")]\n    public GameObject agentPrefab;\n    public int maxAgents = 100;\n\n    [Header("Visualization Settings")]\n    public Color[] agentColors;\n    public float agentSize = 1.0f;\n    public float connectionDistance = 5.0f;\n\n    private List<GameObject> agents = new List<GameObject>();\n    private Dictionary<string, GameObject> agentMap = new Dictionary<string, GameObject>();\n\n    void Start()\n    {\n        InitializeAgents();\n    }\n\n    void InitializeAgents()\n    {\n        for (int i = 0; i < maxAgents; i++)\n        {\n            GameObject agent = Instantiate(\n                agentPrefab,\n                Vector3.zero,\n                Quaternion.identity\n            );\n\n            agent.name = $"Agent_{i:D3}";\n            agents.Add(agent);\n\n            // Set unique color\n            Renderer renderer = agent.GetComponent<Renderer>();\n            if (renderer != null && agentColors.Length > 0)\n            {\n                int colorIndex = i % agentColors.Length;\n                renderer.material.color = agentColors[colorIndex];\n            }\n\n            // Add to map for quick lookup\n            agentMap[agent.name] = agent;\n        }\n    }\n\n    public void UpdateAgentPositions(Dictionary<string, Vector3> agentPositions)\n    {\n        foreach (var kvp in agentPositions)\n        {\n            if (agentMap.ContainsKey(kvp.Key))\n            {\n                agentMap[kvp.Key].transform.position = kvp.Value;\n            }\n        }\n    }\n\n    public void UpdateAgentStates(Dictionary<string, AgentState> agentStates)\n    {\n        foreach (var kvp in agentStates)\n        {\n            if (agentMap.ContainsKey(kvp.Key))\n            {\n                UpdateAgentVisualState(agentMap[kvp.Key], kvp.Value);\n            }\n        }\n    }\n\n    void UpdateAgentVisualState(GameObject agent, AgentState state)\n    {\n        Renderer renderer = agent.GetComponent<Renderer>();\n        if (renderer != null)\n        {\n            // Change color based on state\n            Color stateColor = GetColorForState(state);\n            renderer.material.color = stateColor;\n\n            // Change size based on importance or priority\n            float scale = agentSize * state.importance;\n            agent.transform.localScale = Vector3.one * scale;\n        }\n\n        // Add state-specific visual effects\n        switch (state.status)\n        {\n            case AgentStatus.Busy:\n                AddBusyEffect(agent);\n                break;\n            case AgentStatus.Idle:\n                AddIdleEffect(agent);\n                break;\n            case AgentStatus.Error:\n                AddErrorEffect(agent);\n                break;\n        }\n    }\n\n    Color GetColorForState(AgentState state)\n    {\n        switch (state.status)\n        {\n            case AgentStatus.Busy: return Color.blue;\n            case AgentStatus.Idle: return Color.green;\n            case AgentStatus.Error: return Color.red;\n            case AgentStatus.Charging: return Color.yellow;\n            default: return Color.white;\n        }\n    }\n\n    void AddBusyEffect(GameObject agent)\n    {\n        // Add rotating indicator or other visual effect\n        ParticleSystem busyEffect = agent.GetComponent<ParticleSystem>();\n        if (busyEffect == null)\n        {\n            busyEffect = agent.AddComponent<ParticleSystem>();\n            var main = busyEffect.main;\n            main.startColor = Color.blue;\n            main.startSize = 0.2f;\n        }\n        busyEffect.Play();\n    }\n\n    void AddIdleEffect(GameObject agent)\n    {\n        // Add pulsing effect for idle agents\n        ParticleSystem idleEffect = agent.GetComponent<ParticleSystem>();\n        if (idleEffect == null)\n        {\n            idleEffect = agent.AddComponent<ParticleSystem>();\n            var main = idleEffect.main;\n            main.startColor = Color.green;\n            main.startSize = 0.1f;\n        }\n        idleEffect.Stop();\n    }\n\n    void AddErrorEffect(GameObject agent)\n    {\n        // Add red flashing effect for errors\n        ParticleSystem errorEffect = agent.GetComponent<ParticleSystem>();\n        if (errorEffect == null)\n        {\n            errorEffect = agent.AddComponent<ParticleSystem>();\n            var main = errorEffect.main;\n            main.startColor = Color.red;\n            main.startSize = 0.3f;\n        }\n        errorEffect.Play();\n    }\n\n    void Update()\n    {\n        // Draw connections between nearby agents\n        DrawAgentConnections();\n    }\n\n    void DrawAgentConnections()\n    {\n        // Draw lines between agents within connection distance\n        for (int i = 0; i < agents.Count; i++)\n        {\n            for (int j = i + 1; j < agents.Count; j++)\n            {\n                float distance = Vector3.Distance(\n                    agents[i].transform.position,\n                    agents[j].transform.position\n                );\n\n                if (distance <= connectionDistance)\n                {\n                    Debug.DrawLine(\n                        agents[i].transform.position,\n                        agents[j].transform.position,\n                        Color.cyan * 0.5f\n                    );\n                }\n            }\n        }\n    }\n}\n\n[System.Serializable]\npublic class AgentState\n{\n    public AgentStatus status;\n    public float importance = 1.0f;\n    public float batteryLevel = 100.0f;\n    public string currentTask = "idle";\n}\n\npublic enum AgentStatus\n{\n    Idle,\n    Busy,\n    Error,\n    Charging,\n    Moving\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,i.jsx)(e.h3,{id:"ros-2-communication-in-unity",children:"ROS 2 Communication in Unity"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: ROS 2 communication system for Unity\nusing UnityEngine;\nusing System.Collections;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Std;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Sensor;\n\npublic class ROS2UnityBridge : MonoBehaviour\n{\n    [Header("ROS Connection")]\n    public string rosIP = "127.0.0.1";\n    public int rosPort = 10000;\n\n    [Header("Robot Topics")]\n    public string jointStateTopic = "/joint_states";\n    public string cmdVelTopic = "/cmd_vel";\n    public string odomTopic = "/odom";\n    public string imageTopic = "/camera/color/image_raw";\n\n    private ROSConnection ros;\n    private JointStateMsg currentJointState;\n    private OdometryMsg currentOdometry;\n    private bool isConnected = false;\n\n    void Start()\n    {\n        ConnectToROS();\n        SubscribeToTopics();\n    }\n\n    void ConnectToROS()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Initialize(rosIP, rosPort);\n        isConnected = true;\n    }\n\n    void SubscribeToTopics()\n    {\n        ros.Subscribe<JointStateMsg>(jointStateTopic, OnJointStateReceived);\n        ros.Subscribe<OdometryMsg>(odomTopic, OnOdometryReceived);\n        ros.Subscribe<ImageMsg>(imageTopic, OnImageReceived);\n    }\n\n    void OnJointStateReceived(JointStateMsg jointState)\n    {\n        currentJointState = jointState;\n        // Trigger joint update in visualization\n        UpdateJointVisualization();\n    }\n\n    void OnOdometryReceived(OdometryMsg odometry)\n    {\n        currentOdometry = odometry;\n        // Update robot position in Unity\n        UpdateRobotPosition();\n    }\n\n    void OnImageReceived(ImageMsg image)\n    {\n        // Process camera image\n        ProcessCameraImage(image);\n    }\n\n    void UpdateJointVisualization()\n    {\n        if (currentJointState == null) return;\n\n        // Update robot joints based on received state\n        for (int i = 0; i < currentJointState.name.Count; i++)\n        {\n            string jointName = currentJointState.name[i];\n            double jointPosition = currentJointState.position[i];\n\n            // Find and update corresponding joint in Unity\n            Transform jointTransform = FindJointTransform(jointName);\n            if (jointTransform != null)\n            {\n                jointTransform.localRotation =\n                    Quaternion.Euler(0, (float)jointPosition * Mathf.Rad2Deg, 0);\n            }\n        }\n    }\n\n    void UpdateRobotPosition()\n    {\n        if (currentOdometry == null) return;\n\n        // Update robot position and orientation\n        Vector3 position = new Vector3(\n            (float)currentOdometry.pose.pose.position.x,\n            (float)currentOdometry.pose.pose.position.z, // Unity Y is up\n            (float)currentOdometry.pose.pose.position.y\n        );\n\n        Quaternion rotation = new Quaternion(\n            (float)currentOdometry.pose.pose.orientation.x,\n            (float)currentOdometry.pose.pose.orientation.z,\n            (float)currentOdometry.pose.pose.orientation.y,\n            (float)currentOdometry.pose.pose.orientation.w\n        );\n\n        transform.position = position;\n        transform.rotation = rotation;\n    }\n\n    Transform FindJointTransform(string jointName)\n    {\n        // Find joint in robot hierarchy\n        Transform[] allChildren = GetComponentsInChildren<Transform>();\n        foreach (Transform child in allChildren)\n        {\n            if (child.name == jointName)\n                return child;\n        }\n        return null;\n    }\n\n    public void SendVelocityCommand(float linearX, float angularZ)\n    {\n        if (!isConnected) return;\n\n        var cmd = new TwistMsg();\n        cmd.linear = new Vector3Msg(linearX, 0, 0);\n        cmd.angular = new Vector3Msg(0, 0, angularZ);\n\n        ros.Publish(cmdVelTopic, cmd);\n    }\n\n    public void SendJointCommands(float[] positions)\n    {\n        if (!isConnected) return;\n\n        var cmd = new JointStateMsg();\n        cmd.position = new System.Collections.Generic.List<double>();\n\n        foreach (float pos in positions)\n        {\n            cmd.position.Add(pos);\n        }\n\n        ros.Publish("/joint_commands", cmd);\n    }\n\n    void ProcessCameraImage(ImageMsg image)\n    {\n        // Forward image to camera visualizer\n        CameraFeedVisualizer cameraVis = FindObjectOfType<CameraFeedVisualizer>();\n        if (cameraVis != null)\n        {\n            cameraVis.OnImageReceived(image);\n        }\n    }\n\n    void OnApplicationQuit()\n    {\n        if (ros != null)\n        {\n            ros.Close();\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(e.h3,{id:"rendering-optimization",children:"Rendering Optimization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Performance optimization for large-scale visualization\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class VisualizationOptimizer : MonoBehaviour\n{\n    [Header("LOD Settings")]\n    public float lodDistance = 10.0f;\n    public int maxVisibleAgents = 50;\n\n    [Header("Culling Settings")]\n    public float frustumCullDistance = 50.0f;\n    public bool enableOcclusionCulling = true;\n\n    [Header("Batching Settings")]\n    public bool enableDynamicBatching = true;\n    public bool enableStaticBatching = true;\n\n    private List<Renderer> agentRenderers = new List<Renderer>();\n    private Camera mainCamera;\n\n    void Start()\n    {\n        mainCamera = Camera.main;\n        SetupOptimization();\n    }\n\n    void SetupOptimization()\n    {\n        // Configure Unity rendering settings\n        QualitySettings.vSyncCount = 0; // Disable vsync for performance\n        Application.targetFrameRate = 60;\n\n        // Set up level of detail\n        SetupLODGroups();\n\n        // Configure occlusion culling\n        if (enableOcclusionCulling)\n        {\n            SetupOcclusionCulling();\n        }\n    }\n\n    void SetupLODGroups()\n    {\n        // Create LOD groups for agents\n        foreach (GameObject agent in FindObjectsOfType<GameObject>())\n        {\n            if (agent.name.Contains("Agent"))\n            {\n                SetupAgentLOD(agent);\n            }\n        }\n    }\n\n    void SetupAgentLOD(GameObject agent)\n    {\n        LODGroup lodGroup = agent.GetComponent<LODGroup>();\n        if (lodGroup == null)\n        {\n            lodGroup = agent.AddComponent<LODGroup>();\n        }\n\n        // Create LOD levels\n        LOD[] lods = new LOD[3];\n\n        // High detail (close)\n        Renderer[] highDetailRenderers = agent.GetComponentsInChildren<Renderer>();\n        lods[0] = new LOD(0.5f, highDetailRenderers);\n\n        // Medium detail (medium distance)\n        Renderer[] mediumDetailRenderers = GetMediumDetailRenderers(agent);\n        lods[1] = new LOD(0.2f, mediumDetailRenderers);\n\n        // Low detail (far)\n        Renderer[] lowDetailRenderers = GetLowDetailRenderers(agent);\n        lods[2] = new LOD(0.01f, lowDetailRenderers);\n\n        lodGroup.SetLODs(lods);\n        lodGroup.RecalculateBounds();\n    }\n\n    Renderer[] GetMediumDetailRenderers(GameObject agent)\n    {\n        // Return simplified renderers for medium distance\n        List<Renderer> renderers = new List<Renderer>();\n        foreach (Renderer r in agent.GetComponentsInChildren<Renderer>())\n        {\n            if (ShouldIncludeInMediumLOD(r))\n                renderers.Add(r);\n        }\n        return renderers.ToArray();\n    }\n\n    Renderer[] GetLowDetailRenderers(GameObject agent)\n    {\n        // Return minimal renderers for far distance\n        Renderer mainRenderer = agent.GetComponent<Renderer>();\n        return mainRenderer != null ? new Renderer[] { mainRenderer } : new Renderer[0];\n    }\n\n    bool ShouldIncludeInMediumLOD(Renderer renderer)\n    {\n        // Determine if renderer should be included in medium LOD\n        return renderer.name != "DetailObject"; // Example: exclude detail objects\n    }\n\n    void SetupOcclusionCulling()\n    {\n        // Mark static objects for occlusion culling\n        foreach (GameObject obj in GameObject.FindGameObjectsWithTag("Static"))\n        {\n            obj.GetComponent<Renderer>().receiveGI = ReceiveGI.Lightmaps;\n        }\n    }\n\n    void Update()\n    {\n        OptimizeAgentRendering();\n    }\n\n    void OptimizeAgentRendering()\n    {\n        // Frustum culling\n        foreach (Renderer renderer in agentRenderers)\n        {\n            if (renderer != null)\n            {\n                renderer.enabled = IsInFrustum(renderer.bounds);\n            }\n        }\n\n        // Distance-based culling\n        if (mainCamera != null)\n        {\n            foreach (Renderer renderer in agentRenderers)\n            {\n                if (renderer != null)\n                {\n                    float distance = Vector3.Distance(\n                        mainCamera.transform.position,\n                        renderer.bounds.center\n                    );\n\n                    renderer.enabled = distance <= frustumCullDistance;\n                }\n            }\n        }\n    }\n\n    bool IsInFrustum(Bounds bounds)\n    {\n        if (mainCamera == null) return true;\n\n        Plane[] planes = GeometryUtility.CalculateFrustumPlanes(mainCamera);\n        return GeometryUtility.TestPlanesAABB(planes, bounds);\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"practical-applications-in-humanoid-robotics",children:"Practical Applications in Humanoid Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"teleoperation-interface",children:"Teleoperation Interface"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Advanced teleoperation interface\nusing UnityEngine;\nusing UnityEngine.UI;\n\npublic class HumanoidTeleoperationInterface : MonoBehaviour\n{\n    [Header("Teleoperation Controls")]\n    public Transform robotBase;\n    public Transform cameraRig;\n    public Canvas controlCanvas;\n\n    [Header("Input Mapping")]\n    public KeyCode walkForwardKey = KeyCode.W;\n    public KeyCode walkBackwardKey = KeyCode.S;\n    public KeyCode turnLeftKey = KeyCode.A;\n    public KeyCode turnRightKey = KeyCode.D;\n    public KeyCode jumpKey = KeyCode.Space;\n\n    [Header("Teleoperation Settings")]\n    public float walkSpeed = 2.0f;\n    public float turnSpeed = 50.0f;\n    public float jumpForce = 5.0f;\n\n    private CharacterController characterController;\n    private Vector3 movementDirection;\n    private bool isGrounded;\n\n    void Start()\n    {\n        characterController = robotBase.GetComponent<CharacterController>();\n        if (characterController == null)\n        {\n            characterController = robotBase.gameObject.AddComponent<CharacterController>();\n        }\n    }\n\n    void Update()\n    {\n        HandleTeleoperationInput();\n        ApplyMovement();\n    }\n\n    void HandleTeleoperationInput()\n    {\n        movementDirection = Vector3.zero;\n\n        // Movement input\n        if (Input.GetKey(walkForwardKey))\n            movementDirection += robotBase.forward;\n        if (Input.GetKey(walkBackwardKey))\n            movementDirection -= robotBase.forward;\n        if (Input.GetKey(turnLeftKey))\n            robotBase.Rotate(0, -turnSpeed * Time.deltaTime, 0);\n        if (Input.GetKey(turnRightKey))\n            robotBase.Rotate(0, turnSpeed * Time.deltaTime, 0);\n\n        // Normalize movement direction\n        movementDirection = Vector3.ProjectOnPlane(movementDirection, Vector3.up).normalized;\n\n        // Jump input\n        if (Input.GetKeyDown(jumpKey) && isGrounded)\n        {\n            movementDirection.y = jumpForce;\n            isGrounded = false;\n        }\n    }\n\n    void ApplyMovement()\n    {\n        // Apply gravity\n        if (!isGrounded)\n        {\n            movementDirection.y -= 9.81f * Time.deltaTime;\n        }\n\n        // Move the robot\n        Vector3 movement = movementDirection * walkSpeed * Time.deltaTime;\n        characterController.Move(movement);\n\n        // Update grounded state\n        isGrounded = characterController.isGrounded;\n        if (isGrounded && movementDirection.y < 0)\n        {\n            movementDirection.y = 0;\n        }\n    }\n\n    public void SetTeleoperationMode(bool enabled)\n    {\n        controlCanvas.enabled = enabled;\n        Cursor.visible = enabled;\n        Cursor.lockState = enabled ? CursorLockMode.None : CursorLockMode.Locked;\n    }\n\n    public void SendTeleoperationCommand(Vector3 command)\n    {\n        // Send command to actual robot via ROS\n        var cmd = new RosMessageTypes.Geometry.TwistMsg();\n        cmd.linear = new RosMessageTypes.Geometry.Vector3Msg(\n            command.x, command.y, command.z\n        );\n        cmd.angular = new RosMessageTypes.Geometry.Vector3Msg(0, 0, 0);\n\n        ROSConnection.GetOrCreateInstance().Publish("/cmd_vel", cmd);\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"training-environment",children:"Training Environment"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Training environment for humanoid robot learning\nusing UnityEngine;\nusing System.Collections;\nusing Unity.MLAgents;\nusing Unity.MLAgents.Sensors;\nusing Unity.MLAgents.Actuators;\n\npublic class HumanoidTrainingEnvironment : Agent\n{\n    [Header("Training Settings")]\n    public Transform target;\n    public float targetRadius = 1.0f;\n    public float maxDistance = 10.0f;\n\n    [Header("Reward Settings")]\n    public float reachTargetReward = 10.0f;\n    public float distanceRewardMultiplier = 0.1f;\n    public float timePenalty = -0.01f;\n\n    private HumanoidRobotController robotController;\n    private float episodeStartTime;\n\n    public override void Initialize()\n    {\n        robotController = GetComponent<HumanoidRobotController>();\n        episodeStartTime = Time.time;\n    }\n\n    public override void OnEpisodeBegin()\n    {\n        // Reset robot position\n        transform.position = new Vector3(\n            Random.Range(-maxDistance/2, maxDistance/2),\n            0,\n            Random.Range(-maxDistance/2, maxDistance/2)\n        );\n\n        // Reset target position\n        target.position = new Vector3(\n            Random.Range(-maxDistance/2, maxDistance/2),\n            0,\n            Random.Range(-maxDistance/2, maxDistance/2)\n        );\n\n        // Reset robot state\n        robotController.Reset();\n    }\n\n    public override void CollectObservations(VectorSensor sensor)\n    {\n        // Collect observations for the agent\n        sensor.AddObservation(transform.position); // Current position\n        sensor.AddObservation(target.position);   // Target position\n        sensor.AddObservation(GetDistanceToTarget()); // Distance to target\n        sensor.AddObservation(robotController.GetJointPositions()); // Joint positions\n        sensor.AddObservation(robotController.GetJointVelocities()); // Joint velocities\n        sensor.AddObservation(robotController.GetBodyVelocity()); // Body velocity\n    }\n\n    public override void OnActionReceived(ActionBuffers actions)\n    {\n        // Apply actions to the robot\n        float[] continuousActions = actions.ContinuousActions.ToArray();\n        robotController.ApplyActions(continuousActions);\n\n        // Calculate reward\n        float distanceToTarget = GetDistanceToTarget();\n        float distanceReward = (maxDistance - distanceToTarget) * distanceRewardMultiplier;\n\n        SetReward(timePenalty + distanceReward);\n\n        // Check if target reached\n        if (distanceToTarget < targetRadius)\n        {\n            SetReward(GetReward() + reachTargetReward);\n            EndEpisode();\n        }\n\n        // Check if episode should end due to time limit\n        if (Time.time - episodeStartTime > 30.0f) // 30 seconds max\n        {\n            EndEpisode();\n        }\n    }\n\n    public override void Heuristic(in ActionBuffers actionsOut)\n    {\n        // For testing with keyboard input\n        var continuousActionsOut = actionsOut.ContinuousActions;\n\n        continuousActionsOut[0] = Input.GetAxis("Horizontal"); // Move X\n        continuousActionsOut[1] = Input.GetAxis("Vertical");   // Move Z\n    }\n\n    float GetDistanceToTarget()\n    {\n        return Vector3.Distance(transform.position, target.position);\n    }\n\n    void OnTriggerEnter(Collider other)\n    {\n        if (other.CompareTag("Target"))\n        {\n            SetReward(GetReward() + reachTargetReward);\n            EndEpisode();\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"best-practices-for-unity-robotics",children:"Best Practices for Unity Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"architecture-and-design-patterns",children:"Architecture and Design Patterns"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'// Example: Unity robotics architecture using SOA (Service-Oriented Architecture)\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class UnityRoboticsSystem : MonoBehaviour\n{\n    private Dictionary<string, IRoboticsService> services;\n\n    void Start()\n    {\n        InitializeServices();\n    }\n\n    void InitializeServices()\n    {\n        services = new Dictionary<string, IRoboticsService>();\n\n        // Add services\n        services.Add("visualization", new VisualizationService());\n        services.Add("communication", new CommunicationService());\n        services.Add("input", new InputService());\n        services.Add("physics", new PhysicsService());\n    }\n\n    void Update()\n    {\n        // Update all services\n        foreach (var service in services.Values)\n        {\n            service.Update();\n        }\n    }\n\n    public T GetService<T>() where T : class\n    {\n        foreach (var service in services.Values)\n        {\n            if (service is T)\n                return service as T;\n        }\n        return null;\n    }\n}\n\npublic interface IRoboticsService\n{\n    void Initialize();\n    void Update();\n    void Shutdown();\n}\n\npublic class VisualizationService : IRoboticsService\n{\n    public void Initialize() { /* Initialize visualization system */ }\n    public void Update() { /* Update visualization */ }\n    public void Shutdown() { /* Clean up visualization */ }\n}\n\npublic class CommunicationService : IRoboticsService\n{\n    public void Initialize() { /* Initialize ROS communication */ }\n    public void Update() { /* Handle ROS messages */ }\n    public void Shutdown() { /* Close ROS connections */ }\n}\n\npublic class InputService : IRoboticsService\n{\n    public void Initialize() { /* Initialize input handling */ }\n    public void Update() { /* Process input */ }\n    public void Shutdown() { /* Clean up input */ }\n}\n\npublic class PhysicsService : IRoboticsService\n{\n    public void Initialize() { /* Initialize physics */ }\n    public void Update() { /* Update physics */ }\n    public void Shutdown() { /* Clean up physics */ }\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"Unity provides a powerful platform for advanced visualization and interaction in Physical AI systems, offering photorealistic rendering, sophisticated interaction mechanisms, and integration capabilities with ROS 2. The platform's flexibility allows for the creation of immersive training environments, intuitive teleoperation interfaces, and complex multi-agent simulations that enhance the development and deployment of humanoid robotics systems."}),"\n",(0,i.jsx)(e.p,{children:"The integration of Unity with robotics workflows enables the creation of sophisticated visualization tools that support both development and operational phases of robotic systems. Proper implementation of rendering optimization, interaction systems, and communication protocols ensures that Unity-based visualization systems can handle the complexity and real-time requirements of Physical AI applications."}),"\n",(0,i.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["Unity Robotics Hub Documentation: ",(0,i.jsx)(e.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,i.jsxs)(e.li,{children:["Unity ML-Agents: ",(0,i.jsx)(e.a,{href:"https://github.com/Unity-Technologies/ml-agents",children:"https://github.com/Unity-Technologies/ml-agents"})]}),"\n",(0,i.jsxs)(e.li,{children:["ROS# (ROS Sharp): ",(0,i.jsx)(e.a,{href:"https://github.com/syuntoku14/ROS-TCP-Endpoint",children:"https://github.com/syuntoku14/ROS-TCP-Endpoint"})]}),"\n",(0,i.jsx)(e.li,{children:'"Game Engine Architecture" by Jason Gregory'}),"\n",(0,i.jsx)(e.li,{children:'"Real-Time Rendering" by Tomas Akenine-M\xf6ller et al.'}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453(n,e,t){t.d(e,{R:()=>r,x:()=>s});var i=t(6540);const o={},a=i.createContext(o);function r(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);